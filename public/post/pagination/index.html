<!doctype html><html lang=en dir=auto><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Pagination Optimization: Why Limit-Offset Can Be a Time Bomb and Cursor Pagination as the Solution | Muchlis Dev</title><meta name=keywords content="Golang,Database,Optimization,Best Practices"><meta name=description content="Comparing the most optimal methods for implementing pagination in Golang backend. Implementing Cursor-Based Pagination."><meta name=author content="Muchlis"><link rel=canonical href=http://localhost:1313/post/pagination/><meta name=google-site-verification content="G-F1ZZCKLSJF"><link crossorigin=anonymous href=/assets/css/stylesheet.8fe10233a706bc87f2e08b3cf97b8bd4c0a80f10675a143675d59212121037c0.css integrity="sha256-j+ECM6cGvIfy4Is8+XuL1MCoDxBnWhQ2ddWSEhIQN8A=" rel="preload stylesheet" as=style><link rel=icon href=http://localhost:1313/icon/favicon.ico><link rel=icon type=image/png sizes=16x16 href=http://localhost:1313/icon/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=http://localhost:1313/icon/favicon-32x32.png><link rel=apple-touch-icon href=http://localhost:1313/icon/apple-touch-icon.png><link rel=mask-icon href=http://localhost:1313/icon/apple-touch-icon.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=http://localhost:1313/post/pagination/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-F1ZZCKLSJF"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-F1ZZCKLSJF")}</script><meta property="og:url" content="http://localhost:1313/post/pagination/"><meta property="og:site_name" content="Muchlis Dev"><meta property="og:title" content="Pagination Optimization: Why Limit-Offset Can Be a Time Bomb and Cursor Pagination as the Solution"><meta property="og:description" content="Comparing the most optimal methods for implementing pagination in Golang backend. Implementing Cursor-Based Pagination."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="post"><meta property="article:published_time" content="2024-08-11T13:57:10+08:00"><meta property="article:modified_time" content="2024-08-11T13:57:10+08:00"><meta property="article:tag" content="Golang"><meta property="article:tag" content="Database"><meta property="article:tag" content="Optimization"><meta property="article:tag" content="Best Practices"><meta property="og:image" content="http://localhost:1313/img/pagination/pagination-performance.webp"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="http://localhost:1313/img/pagination/pagination-performance.webp"><meta name=twitter:title content="Pagination Optimization: Why Limit-Offset Can Be a Time Bomb and Cursor Pagination as the Solution"><meta name=twitter:description content="Comparing the most optimal methods for implementing pagination in Golang backend. Implementing Cursor-Based Pagination."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"http://localhost:1313/post/"},{"@type":"ListItem","position":2,"name":"Pagination Optimization: Why Limit-Offset Can Be a Time Bomb and Cursor Pagination as the Solution","item":"http://localhost:1313/post/pagination/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Pagination Optimization: Why Limit-Offset Can Be a Time Bomb and Cursor Pagination as the Solution","name":"Pagination Optimization: Why Limit-Offset Can Be a Time Bomb and Cursor Pagination as the Solution","description":"Comparing the most optimal methods for implementing pagination in Golang backend. Implementing Cursor-Based Pagination.","keywords":["Golang","Database","Optimization","Best Practices"],"articleBody":"Pagination is a technique for dividing database query results into smaller chunks. Using LIMIT OFFSET queries is the most commonly used method. However, this method has several weaknesses, especially in terms of performance on very large datasets. This article will discuss problems that arise when using LIMIT OFFSET and explore more efficient alternatives, such as cursor-based pagination and seek method.\nThe Importance of Pagination and Its Challenges Pagination has several benefits, such as:\nPerformance Maintenance: Returning large data all at once is slow and resource-intensive. By dividing data into smaller chunks, APIs can return data faster and with fewer resources. Processing large data also requires a lot of memory, which can be a problem for devices with limited resources like mobile phones. By using pagination, APIs can limit the amount of data that needs to be stored in memory at any given time.\nUser Experience: For client applications that display data to users, pagination can improve user experience by providing a faster and more responsive interface. Users can see initial results quickly and can request additional data as needed.\nHowever, it’s important to remember that pagination is not always a perfect solution. On very large datasets, pagination techniques can face challenges that will become very fatal later on.\nLIMIT OFFSET Pagination Here we will discuss the disadvantages of pagination using LIMIT OFFSET and how to minimize these disadvantages.\nWhy is LIMIT OFFSET Slow for Large Datasets? When dealing with very large datasets, pagination using LIMIT OFFSET often experiences performance degradation. This is because every time we request a new page, the database must scan the entire table from the beginning to find the appropriate data, even though we only need a small portion of the data.\nHere’s an example SQL query showing how LIMIT and OFFSET are applied:\nSELECT * FROM records ORDER BY id LIMIT 10 OFFSET 1000; Explanation:\nLIMIT determines the maximum number of rows returned.\nOFFSET determines how many rows to skip before starting to return results.\nIn the example above, the query will actually scan the first 1000 rows, discard unnecessary data, and return the next 10 rows. If the table has millions of rows, skipping a large number of rows with a large offset will make the query run slower because the database must sort and scan all those rows before returning results.\nThis means if the client makes requests for page 2, page 3 and so on, it will cause the database to process many times more data compared to the amount actually returned to the client.\nAs an illustration, assuming 1 page displays 100 data:\nFor page 1: OFFSET 0, LIMIT 100 -\u003e scans and returns 100 rows. For page 2: OFFSET 100, LIMIT 100 -\u003e scans and discards 100 rows, then scans and returns the next 100 rows. For page 3: OFFSET 200, LIMIT 100 -\u003e scans and discards 200 rows, then scans and returns the next 100 rows. For page 100: OFFSET 10000, LIMIT 100 -\u003e scans and discards 10000 rows, then scans and returns the next 100 rows. The larger the offset value, the more rows need to be scanned and discarded, making the query slower and less efficient. This becomes very bad for tables with millions of rows because processing and discarding a lot of data every time there’s a new page request.\nWorst case example for this: Client wants to get all data by scanning from page 1 to the last page. Looking at the behavior, this is usually needed by other services that use our service as their data source.\nImagine we want to read a very thick book page by page. If we use the LIMIT and OFFSET method, we have to open the book from the beginning every time we want to read the next page. This is certainly very inefficient, because we will repeatedly open the same pages. In the database context, this is the same as making the database work harder than it should. Therefore, if the goal is to get all data, it’s better to take the entire book (data) at once without pagination, then read it (process it) in the application.\nImpact of COUNT(*) Query on Performance Not only that, in pagination implementation using LIMIT and OFFSET, the SELECT COUNT(*) query is often used to count the total number of rows in the dataset. This information is needed to compile pagination metadata, such as total number of pages and total items, which is then returned in the API response.\nFor example, the API response might have a structure like this:\n{ \"message\": \"successfully fetch data\", \"data\": [ {} ], \"meta\": { \"current_page\": 1, \"page_size\": 100, \"total_count\": 3000, \"total_page\": 30 }, \"trace_id\": \"5b427ba9ab30002d347ea17cf8000cca\" } To generate this metadata, the backend needs to perform two queries:\nTo retrieve data with LIMIT and OFFSET SELECT * FROM users LIMIT 100 OFFSET 0; To count the total number of rows with COUNT(*) SELECT COUNT(*) FROM users; Surprisingly, using COUNT(*) on large datasets can result in significant performance degradation. This is due to:\nFull table scan: The database needs to scan the entire table to count the number of rows, especially if there are no suitable indexes. Lack of index optimization: COUNT(*) often cannot be optimized with indexes, so query execution time becomes longer. Concurrency and locking issues: COUNT(*) queries can cause locks with other queries and hinder system performance. High I/O load: The process of counting rows requires many read-write operations on the database disk. This problem may not be clearly visible early in development, but will become more apparent as data volume continues to grow. Therefore, I highly recommend that we can determine the most suitable pagination technique from the beginning of development. Alternative techniques and optimizations can be good solutions to overcome them.\nLIMIT OFFSET Database Query Optimization It turns out that queries for pagination with LIMIT OFFSET can still be optimized. How to do it? I actually found this technique in a library used in another language, PHP Laravel. which can be found in this library: https://github.com/hammerstonedev/fast-paginate What is done to make the performance better?\nselect * from users -- The full data that you want to show your users. where users.id in ( -- The \"deferred join\" or subquery, in our case. select id from users -- The pagination, accessing as little data as possible - ID only. limit 15 offset 150000 ) The idea is to apply LIMIT and OFFSET on data with a smaller scope, then search for the results to create complete data.\nHowever, the SELECT COUNT(*) query may not be optimizable. So, this optimization technique on LIMIT OFFSET queries doesn’t completely solve the problems I experienced, especially for SELECT COUNT(*) queries on large datasets. This is evident from the monitoring results I conducted.\nThe monitoring results show a significant performance difference between query to retrieve data vs COUNT(*) query, especially when many requests come in simultaneously.\nThis is also supported by similar problems discussed on the internet such as:\nhttps://stackoverflow.com/questions/55018986/postgresql-select-count-query-takes-long-time https://www.reddit.com/r/PostgreSQL/comments/140b4xy/select_count_is_slow_in_large_tables/ https://tunghatbh.medium.com/postgresql-slow-count-query-c93c30792606 From this case study, I draw several important conclusions:\nNumber of N queries doesn't always determine performance: It’s not always true that the fewer query requests we run, the better the performance. In some cases, splitting complex queries into several smaller queries can actually improve overall performance. Indexes are not always optimal for COUNT(*): Although indexes can improve query performance in general, in COUNT(*) cases indexes are not always effective. Importance of benchmarking: Comparing performance before and after query changes is the most accurate way to measure the impact of an optimization. Because different queries and data structures may require different optimization methods. Cursor! As an Alternative to Limit Offset Cursor-based Pagination Explanation Cursor-based pagination uses a unique value from a column (usually the sorted column) as a “cursor” to mark the current position in the query results. Instead of using offset, we send the cursor from the previous result to get the next page. This is more efficient because the database can skip values and only needs to look for records that have cursor values greater than the previous cursor value.\nSELECT * FROM users WHERE sort_column \u003e 'cursor_value' ORDER BY sort_column LIMIT 10; Advantages of Cursor-based Pagination Better performance: No need to scan the entire table for each page request. Consistent results: Query results are always the same, regardless of data changes that occur between requests. For example, pagination on LIMIT OFFSET will be inconsistent if data on previous pages is deleted. Infinity Loading UX: Cursor pagination is very suitable for web and mobile user experience that usually implements infinity loading. Disadvantages of Cursor-based Pagination More complex implementation: Requires careful planning in choosing the right cursor column. Not suitable for all types of queries and UX: Only effective for queries sorted by one or several columns. Stateful: Because it must pass the cursor Sorting merged with cursor: The order of displayed data is always proportional to the cursor used. Implementation Example As an example, API response with cursor pagination might have a structure like this:\nEndpoint: {baseURL}/users?limit=3\u0026cursor= Query Param: limit: amount of data displayed. cursor: cursor input, for the first page fill in blank. cursor_type: what field is used as cursor, usually has a default value, in this example using ulid descending. { \"message\": \"successfully fetch data\", \"data\": [ { \"ulid\": \"01J4EXF94RZA4AZG1C0A0C2RKF\", \"name\": \"muchlis\" }, { \"ulid\": \"01J4EXF94RWZVWS9NVEZMQ3R1N\", \"name\": \"monkey d luffy\" }, { \"ulid\": \"01J4EXF94RT7G5CRH047MC0EF1\", \"name\": \"portgas d ace\" } ], \"meta\": { \"current_cursor\": \"\", \"next_cursor\": \"01J4EXF94RT7G5CRH047MC0EF1\", \"next_page\": \"/users?limit=3\u0026cursor=01J4EXF94RT7G5CRH047MC0EF1\", \"prev_cursor\": \"\", \"prev_page\": \"/users?limit=3\u0026cursor=\" }, \"trace_id\": \"5b427ba9ab30002d347ea17cf8000cca\" } Repo Layer:\nI use raw queries for easier readability. But in reality I usually use sql builders like golang squirrel or goqu.\nfunc (r *repo) FetchUserByUlid(ctx context.Context, cursorID string, limit uint64) ([]entity.User, error) { ctx, cancel := context.WithTimeout(ctx, 2*time.Second) defer cancel() var sqlStatement string var args []interface{} if cursorID != \"\" { sqlStatement = ` SELECT id, name FROM users WHERE id \u003c $1 ORDER BY id DESC LIMIT $2; ` args = append(args, cursorID, limit) } else { sqlStatement = ` SELECT id, name FROM users ORDER BY id DESC LIMIT $1; ` args = append(args, limit) } // Execute the query rows, err := r.db.Query(ctx, sqlStatement, args...) if err != nil { return nil, fmt.Errorf(\"failed to execute query: %w\", err) } defer rows.Close() users := make([]entity.User, 0) // [SKIP] Parse the results // [SKIP] Check for errors after iterating over rows return users, nil } Service Layer:\nAt the service layer, there is logic where we have to get more data than what will be displayed to know whether the next data exists or not.\nfunc (s *Service) FetchAllUsersWithCursor(ctx context.Context, cursor string, limit uint64) ([]entity.User, *string /*next cursor*/, error) { // [SKIP] validation, tracer etc // Call repo layer to retrieve data // Add Limit +1 so we know if there is continuation data or not // This excess data will be discarded later results, err := s.repo.FetchUserByUlid(ctx, cursor, limit+1) if err != nil { return nil, nil, fmt.Errorf(\"error FetchUserByUlid: %w\", err) } // Determine next cursor var nextCursor *string if len(results) \u003e int(limit) { nextCursorID := results[limit-1].ID // Set cursor if more data than limit is found nextCursor = \u0026nextCursorID results = results[:limit] // Remove excess data } else { nextCursor = nil // If there is no excess data, the next cursor is set to nil } // [SKIP] Convert results return results, nextCursor, nil } Assuming using Clean Architecture or Hexagonal Architecture\n+-------------------------------------+ | HTTP Handler | | (Handling HTTP requests and | | responses, routing, etc.) | +----------------+--------------------+ | v +----------------+--------------------+ | Service | | (Business logic, orchestrating the | | application flow, validation, | | calling Repositories) | +----------------+--------------------+ | v +----------------+--------------------+ | Repository | | (Data access layer, interacting with| | the database, etc.) | +-------------------------------------+ In the code example above, the remaining layer is the HTTP Handler which serves as the View, where that layer is responsible for creating other values from the service layer process results such as temporarily storing current_cursor, creating next_page values from the FetchAllUsersWithCursor() return value and various other values for responses that require the HTTP Handler Framework.\nThat was an example of a simplified cursor pagination implementation so we get a little picture of its complexity. Even in the code above I intentionally skipped several things below because they are optional.\nPrevious_Page requires implementation that is the opposite of the default SQL Query. Instead of using cursor and order default WHERE id \u003c $1 ORDER BY id DESC, it becomes WHERE id \u003e $1 ORDER BY id ASC with cursor being the first value of the data displayed on the current page. The possibility of cursors and orders that require 2 keys or even more. More strict value validation for Cursor and OrderBy types. Benchmark: Analysis:\nLimit-Offset Pagination has response times that start to increase significantly after page 50 (meaning at data depth 50,000), showing poor scaling for large datasets. Limit-Offset + Query Count Pagination (run together with goroutine) Slightly slower than regular Limit-Offset, which shows additional overhead. The additional overhead from this count will be felt when requests are run in parallel. While the test above was done sequentially. Cursor Pagination is the most efficient and stable, suitable for large datasets with many pages. Notes:\nThis comparison compares all methods using uniform specifications and conditions. Network latency, structure and amount of data can affect results. So, just rely on the comparison, because the numbers will vary greatly depending on each condition. The data used includes 100,000 user data entries that are left-joined with 2 small tables with extreme pagination trials of 1,000 entries per page. Testing was done sequentially, page by page. This test does not include other factors that are actually important such as memory usage, CPU, rows computed in the database. Here I try to make minimal effort. Theoretically alone we can actually estimate which method is superior. This benchmark confirms that. Limit-Offset Pagination has the advantage of ease of implementation, with weaknesses that will only be felt when our application reaches a level where the amount of data becomes very large. This weakness can also be overcome by providing indexed range and filtering predetermined data to users (such as when displaying bank transaction data that must determine the month).\nOn the other hand, although faster and more stable, Cursor-Based Pagination is slightly more complicated to implement and has certain limitations that may make it less suitable for all types of cases.\nThe saying premature optimization is the root of all evil reminds us that optimization that is too early can be a problem, but here in my personal opinion, avoiding mistakes from the start doesn’t mean it’s a bad thing either. In fact, making optimal architectural and design decisions, such as choosing Cursor-Based Pagination over Limit-Offset, can be considered a wise decision-making, not just premature optimization. Essentially, understanding the trade-offs of each choice and choosing the right solution for specific needs is a more appropriate approach in software development.\n","wordCount":"2492","inLanguage":"en","image":"http://localhost:1313/img/pagination/pagination-performance.webp","datePublished":"2024-08-11T13:57:10+08:00","dateModified":"2024-08-11T13:57:10+08:00","author":{"@type":"Person","name":"Muchlis"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:1313/post/pagination/"},"publisher":{"@type":"Organization","name":"Muchlis Dev","logo":{"@type":"ImageObject","url":"http://localhost:1313/icon/favicon.ico"}}}</script><link rel=stylesheet href=http://localhost:1313/css/custom-styles.min.846e2c0c38b3403ffecfec3d9c9b227dcfa79e75b178a91e1a26ae745cf5da5a.css><script src=http://localhost:1313/js/clickable-image.min.64e4ed1fd2302afde6a6750edcf663d18d6bf3b36d95ac130501827d8732c7a3.js defer></script></head><body class=dark id=top><script>localStorage.getItem("pref-theme")==="light"&&document.body.classList.remove("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://localhost:1313/ accesskey=h title="Home (Alt + H)"><img src=http://localhost:1313/icon/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=http://localhost:1313/archives/ title=Archives><span>Archives</span></a></li><li><a href=http://localhost:1313/tags/ title=Tags><span>Tags</span></a></li><li><a href=http://localhost:1313/search title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://muchlis.dev title="Portfolio (2021)"><span>Portfolio (2021)</span>&nbsp;
<svg fill="none" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=http://localhost:1313/>Home</a>&nbsp;»&nbsp;<a href=http://localhost:1313/post/>Posts</a></div><h1 class="post-title entry-hint-parent">Pagination Optimization: Why Limit-Offset Can Be a Time Bomb and Cursor Pagination as the Solution</h1><div class=post-description>Comparing the most optimal methods for implementing pagination in Golang backend. Implementing Cursor-Based Pagination.</div><div class=post-meta><span title='2024-08-11 13:57:10 +0800 WITA'>August 11, 2024</span>&nbsp;·&nbsp;12 min&nbsp;·&nbsp;2492 words&nbsp;·&nbsp;Muchlis&nbsp;|&nbsp;<a href=https://github.com/muchlist/paper/tree/main/content/post/pagination.en.md rel="noopener noreferrer edit" target=_blank>Suggest Changes</a></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#the-importance-of-pagination-and-its-challenges>The Importance of Pagination and Its Challenges</a></li><li><a href=#limit-offset-pagination>LIMIT OFFSET Pagination</a><ul><li><a href=#why-is-limit-offset-slow-for-large-datasets>Why is LIMIT OFFSET Slow for Large Datasets?</a></li><li><a href=#impact-of-count-query-on-performance>Impact of COUNT(*) Query on Performance</a></li><li><a href=#limit-offset-database-query-optimization>LIMIT OFFSET Database Query Optimization</a></li></ul></li><li><a href=#cursor-as-an-alternative-to-limit-offset>Cursor! As an Alternative to Limit Offset</a><ul><li><a href=#cursor-based-pagination-explanation>Cursor-based Pagination Explanation</a></li><li><a href=#implementation-example>Implementation Example</a></li><li><a href=#benchmark>Benchmark:</a></li></ul></li></ul></nav></div></details></div><div class=post-content><p>Pagination is a technique for dividing database query results into smaller chunks. Using LIMIT OFFSET queries is the most commonly used method. However, this method has several weaknesses, especially in terms of performance on very large datasets. This article will discuss problems that arise when using LIMIT OFFSET and explore more efficient alternatives, such as cursor-based pagination and seek method.</p><h2 id=the-importance-of-pagination-and-its-challenges>The Importance of Pagination and Its Challenges<a hidden class=anchor aria-hidden=true href=#the-importance-of-pagination-and-its-challenges>#</a></h2><p>Pagination has several benefits, such as:</p><ul><li><p>Performance Maintenance: Returning large data all at once is slow and resource-intensive. By dividing data into smaller chunks, APIs can return data faster and with fewer resources. Processing large data also requires a lot of memory, which can be a problem for devices with limited resources like mobile phones. By using pagination, APIs can limit the amount of data that needs to be stored in memory at any given time.</p></li><li><p>User Experience: For client applications that display data to users, pagination can improve user experience by providing a faster and more responsive interface. Users can see initial results quickly and can request additional data as needed.</p></li></ul><p>However, it&rsquo;s important to remember that pagination is not always a perfect solution. On very large datasets, pagination techniques can face challenges that will become very fatal later on.</p><h2 id=limit-offset-pagination>LIMIT OFFSET Pagination<a hidden class=anchor aria-hidden=true href=#limit-offset-pagination>#</a></h2><p>Here we will discuss the disadvantages of pagination using LIMIT OFFSET and how to minimize these disadvantages.</p><h3 id=why-is-limit-offset-slow-for-large-datasets>Why is LIMIT OFFSET Slow for Large Datasets?<a hidden class=anchor aria-hidden=true href=#why-is-limit-offset-slow-for-large-datasets>#</a></h3><p>When dealing with very large datasets, pagination using LIMIT OFFSET often experiences performance degradation. This is because every time we request a new page, the database must scan the entire table from the beginning to find the appropriate data, even though we only need a small portion of the data.</p><p>Here&rsquo;s an example SQL query showing how LIMIT and OFFSET are applied:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sql data-lang=sql><span class=line><span class=cl><span class=k>SELECT</span><span class=w> </span><span class=o>*</span><span class=w> </span><span class=k>FROM</span><span class=w> </span><span class=n>records</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>ORDER</span><span class=w> </span><span class=k>BY</span><span class=w> </span><span class=n>id</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>LIMIT</span><span class=w> </span><span class=mi>10</span><span class=w> </span><span class=k>OFFSET</span><span class=w> </span><span class=mi>1000</span><span class=p>;</span><span class=w>
</span></span></span></code></pre></div><p>Explanation:</p><p><code>LIMIT</code> determines the maximum number of rows returned.<br><code>OFFSET</code> determines how many rows to skip before starting to return results.</p><p>In the example above, the query will actually scan the first 1000 rows, discard unnecessary data, and return the next 10 rows. If the table has millions of rows, skipping a large number of rows with a large offset will make the query run slower because the database must sort and scan all those rows before returning results.</p><p>This means if the client makes requests for page 2, page 3 and so on, it will cause the database to process many times more data compared to the amount actually returned to the client.</p><p>As an illustration, assuming 1 page displays 100 data:</p><ul><li><code>For page 1: OFFSET 0, LIMIT 100</code> -> scans and returns 100 rows.</li><li><code>For page 2: OFFSET 100, LIMIT 100</code> -> scans and discards 100 rows, then scans and returns the next 100 rows.</li><li><code>For page 3: OFFSET 200, LIMIT 100</code> -> scans and discards 200 rows, then scans and returns the next 100 rows.</li><li><code>For page 100: OFFSET 10000, LIMIT 100</code> -> scans and discards 10000 rows, then scans and returns the next 100 rows.</li></ul><p>The larger the offset value, the more rows need to be scanned and discarded, making the query slower and less efficient. This becomes very bad for tables with millions of rows because processing and discarding a lot of data every time there&rsquo;s a new page request.</p><p>Worst case example for this: Client wants to get all data by scanning from page 1 to the last page. Looking at the behavior, this is usually needed by other services that use our service as their data source.</p><p>Imagine we want to read a very thick book page by page. If we use the LIMIT and OFFSET method, we have to open the book from the beginning every time we want to read the next page. This is certainly very inefficient, because we will repeatedly open the same pages. In the database context, this is the same as making the database work harder than it should. Therefore, if the goal is to get <code>all data</code>, it&rsquo;s better to take the entire book (data) at once without pagination, then read it (process it) in the application.</p><h3 id=impact-of-count-query-on-performance>Impact of COUNT(*) Query on Performance<a hidden class=anchor aria-hidden=true href=#impact-of-count-query-on-performance>#</a></h3><p>Not only that, in pagination implementation using LIMIT and OFFSET, the <code>SELECT COUNT(*)</code> query is often used to count the total number of rows in the dataset. This information is needed to compile pagination metadata, such as total number of pages and total items, which is then returned in the API response.</p><p>For example, the API response might have a structure like this:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;message&#34;</span><span class=p>:</span> <span class=s2>&#34;successfully fetch data&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;data&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=p>{}</span>
</span></span><span class=line><span class=cl>    <span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;meta&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=nt>&#34;current_page&#34;</span><span class=p>:</span> <span class=mi>1</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=nt>&#34;page_size&#34;</span><span class=p>:</span> <span class=mi>100</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=nt>&#34;total_count&#34;</span><span class=p>:</span> <span class=mi>3000</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=nt>&#34;total_page&#34;</span><span class=p>:</span> <span class=mi>30</span>
</span></span><span class=line><span class=cl>    <span class=p>},</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;trace_id&#34;</span><span class=p>:</span> <span class=s2>&#34;5b427ba9ab30002d347ea17cf8000cca&#34;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>To generate this metadata, the backend needs to perform two queries:</p><ol><li>To retrieve data with LIMIT and OFFSET</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-sql data-lang=sql><span class=line><span class=cl><span class=k>SELECT</span><span class=w> </span><span class=o>*</span><span class=w> </span><span class=k>FROM</span><span class=w> </span><span class=n>users</span><span class=w> </span><span class=k>LIMIT</span><span class=w> </span><span class=mi>100</span><span class=w> </span><span class=k>OFFSET</span><span class=w> </span><span class=mi>0</span><span class=p>;</span><span class=w>
</span></span></span></code></pre></div><ol start=2><li>To count the total number of rows with COUNT(*)</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-sql data-lang=sql><span class=line><span class=cl><span class=k>SELECT</span><span class=w> </span><span class=k>COUNT</span><span class=p>(</span><span class=o>*</span><span class=p>)</span><span class=w> </span><span class=k>FROM</span><span class=w> </span><span class=n>users</span><span class=p>;</span><span class=w>
</span></span></span></code></pre></div><p>Surprisingly, using COUNT(*) on large datasets can result in significant performance degradation. This is due to:</p><ul><li><code>Full table scan</code>: The database needs to scan the entire table to count the number of rows, especially if there are no suitable indexes.</li><li><code>Lack of index optimization</code>: COUNT(*) often cannot be optimized with indexes, so query execution time becomes longer.</li><li><code>Concurrency and locking issues</code>: COUNT(*) queries can cause locks with other queries and hinder system performance.</li><li><code>High I/O load</code>: The process of counting rows requires many read-write operations on the database disk.</li></ul><p>This problem may not be clearly visible early in development, but will become more apparent as data volume continues to grow. Therefore, I highly recommend that we can determine the most suitable pagination technique from the beginning of development. Alternative techniques and optimizations can be good solutions to overcome them.</p><h3 id=limit-offset-database-query-optimization>LIMIT OFFSET Database Query Optimization<a hidden class=anchor aria-hidden=true href=#limit-offset-database-query-optimization>#</a></h3><p>It turns out that queries for pagination with LIMIT OFFSET can still be optimized. How to do it?
I actually found this technique in a library used in another language, PHP Laravel. which can be found in this library: <a href=https://github.com/hammerstonedev/fast-paginate>https://github.com/hammerstonedev/fast-paginate</a>
What is done to make the performance better?</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sql data-lang=sql><span class=line><span class=cl><span class=k>select</span><span class=w> </span><span class=o>*</span><span class=w> </span><span class=k>from</span><span class=w> </span><span class=n>users</span><span class=w>              </span><span class=c1>-- The full data that you want to show your users.
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=w>    </span><span class=k>where</span><span class=w> </span><span class=n>users</span><span class=p>.</span><span class=n>id</span><span class=w> </span><span class=k>in</span><span class=w> </span><span class=p>(</span><span class=w>          </span><span class=c1>-- The &#34;deferred join&#34; or subquery, in our case.
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=w>        </span><span class=k>select</span><span class=w> </span><span class=n>id</span><span class=w> </span><span class=k>from</span><span class=w> </span><span class=n>users</span><span class=w>     </span><span class=c1>-- The pagination, accessing as little data as possible - ID only.
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=w>        </span><span class=k>limit</span><span class=w> </span><span class=mi>15</span><span class=w> </span><span class=k>offset</span><span class=w> </span><span class=mi>150000</span><span class=w>      
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=p>)</span><span class=w>
</span></span></span></code></pre></div><p>The idea is to apply LIMIT and OFFSET on data with a smaller scope, then search for the results to create complete data.</p><p>However, the <code>SELECT COUNT(*)</code> query may not be optimizable. So, this optimization technique on <code>LIMIT OFFSET</code> queries doesn&rsquo;t completely solve the problems I experienced, especially for <code>SELECT COUNT(*)</code> queries on large datasets. This is evident from the monitoring results I conducted.</p><figure><img src=/img/pagination/jaeger-trace-query-count.webp alt="jaeger trace query count" class="clickable-image lazyload" data-src=/img/pagination/jaeger-trace-query-count.webp loading=lazy></figure><p>The monitoring results show a significant performance difference between <code>query to retrieve data</code> vs <code>COUNT(*) query</code>, especially when many requests come in simultaneously.</p><p>This is also supported by similar problems discussed on the internet such as:</p><ul><li><a href=https://stackoverflow.com/questions/55018986/postgresql-select-count-query-takes-long-time>https://stackoverflow.com/questions/55018986/postgresql-select-count-query-takes-long-time</a></li><li><a href=https://www.reddit.com/r/PostgreSQL/comments/140b4xy/select_count_is_slow_in_large_tables/>https://www.reddit.com/r/PostgreSQL/comments/140b4xy/select_count_is_slow_in_large_tables/</a></li><li><a href=https://tunghatbh.medium.com/postgresql-slow-count-query-c93c30792606>https://tunghatbh.medium.com/postgresql-slow-count-query-c93c30792606</a></li></ul><p>From this case study, I draw several important conclusions:</p><ul><li><code>Number of N queries doesn't always determine performance</code>: It&rsquo;s not always true that the fewer query requests we run, the better the performance. In some cases, splitting complex queries into several smaller queries can actually improve overall performance.</li><li><code>Indexes are not always optimal for COUNT(*)</code>: Although indexes can improve query performance in general, in COUNT(*) cases indexes are not always effective.</li><li><code>Importance of benchmarking</code>: Comparing performance before and after query changes is the most accurate way to measure the impact of an optimization. Because different queries and data structures may require different optimization methods.</li></ul><h2 id=cursor-as-an-alternative-to-limit-offset>Cursor! As an Alternative to Limit Offset<a hidden class=anchor aria-hidden=true href=#cursor-as-an-alternative-to-limit-offset>#</a></h2><h3 id=cursor-based-pagination-explanation>Cursor-based Pagination Explanation<a hidden class=anchor aria-hidden=true href=#cursor-based-pagination-explanation>#</a></h3><p>Cursor-based pagination uses a unique value from a column (usually the sorted column) as a &ldquo;cursor&rdquo; to mark the current position in the query results. Instead of using offset, we send the cursor from the previous result to get the next page. This is more efficient because the database can skip values and only needs to look for records that have cursor values greater than the previous cursor value.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sql data-lang=sql><span class=line><span class=cl><span class=k>SELECT</span><span class=w> </span><span class=o>*</span><span class=w> </span><span class=k>FROM</span><span class=w> </span><span class=n>users</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>WHERE</span><span class=w> </span><span class=n>sort_column</span><span class=w> </span><span class=o>&gt;</span><span class=w> </span><span class=s1>&#39;cursor_value&#39;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>ORDER</span><span class=w> </span><span class=k>BY</span><span class=w> </span><span class=n>sort_column</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>LIMIT</span><span class=w> </span><span class=mi>10</span><span class=p>;</span><span class=w>
</span></span></span></code></pre></div><h4 id=advantages-of-cursor-based-pagination>Advantages of Cursor-based Pagination<a hidden class=anchor aria-hidden=true href=#advantages-of-cursor-based-pagination>#</a></h4><ul><li><code>Better performance</code>: No need to scan the entire table for each page request.</li><li><code>Consistent results</code>: Query results are always the same, regardless of data changes that occur between requests. For example, pagination on LIMIT OFFSET will be inconsistent if data on previous pages is deleted.</li><li><code>Infinity Loading UX</code>: Cursor pagination is very suitable for web and mobile user experience that usually implements infinity loading.</li></ul><h4 id=disadvantages-of-cursor-based-pagination>Disadvantages of Cursor-based Pagination<a hidden class=anchor aria-hidden=true href=#disadvantages-of-cursor-based-pagination>#</a></h4><ul><li><code>More complex implementation</code>: Requires careful planning in choosing the right cursor column.</li><li><code>Not suitable for all types of queries and UX</code>: Only effective for queries sorted by one or several columns.</li><li><code>Stateful</code>: Because it must pass the cursor</li><li><code>Sorting merged with cursor</code>: The order of displayed data is always proportional to the cursor used.</li></ul><h3 id=implementation-example>Implementation Example<a hidden class=anchor aria-hidden=true href=#implementation-example>#</a></h3><p>As an example, API response with cursor pagination might have a structure like this:</p><ul><li><code>Endpoint</code>: {baseURL}/users?limit=3&amp;cursor=</li><li><code>Query Param</code>:<ul><li><code>limit</code>: amount of data displayed.</li><li><code>cursor</code>: cursor input, for the first page fill in blank.</li><li><code>cursor_type</code>: what field is used as cursor, usually has a default value, in this example using <code>ulid</code> descending.</li></ul></li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;message&#34;</span><span class=p>:</span> <span class=s2>&#34;successfully fetch data&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;data&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=nt>&#34;ulid&#34;</span><span class=p>:</span> <span class=s2>&#34;01J4EXF94RZA4AZG1C0A0C2RKF&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=nt>&#34;name&#34;</span><span class=p>:</span> <span class=s2>&#34;muchlis&#34;</span>
</span></span><span class=line><span class=cl>        <span class=p>},</span>
</span></span><span class=line><span class=cl>        <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=nt>&#34;ulid&#34;</span><span class=p>:</span> <span class=s2>&#34;01J4EXF94RWZVWS9NVEZMQ3R1N&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=nt>&#34;name&#34;</span><span class=p>:</span> <span class=s2>&#34;monkey d luffy&#34;</span>
</span></span><span class=line><span class=cl>        <span class=p>},</span>
</span></span><span class=line><span class=cl>        <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=nt>&#34;ulid&#34;</span><span class=p>:</span> <span class=s2>&#34;01J4EXF94RT7G5CRH047MC0EF1&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=nt>&#34;name&#34;</span><span class=p>:</span> <span class=s2>&#34;portgas d ace&#34;</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;meta&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=nt>&#34;current_cursor&#34;</span><span class=p>:</span> <span class=s2>&#34;&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=nt>&#34;next_cursor&#34;</span><span class=p>:</span> <span class=s2>&#34;01J4EXF94RT7G5CRH047MC0EF1&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=nt>&#34;next_page&#34;</span><span class=p>:</span> <span class=s2>&#34;/users?limit=3&amp;cursor=01J4EXF94RT7G5CRH047MC0EF1&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=nt>&#34;prev_cursor&#34;</span><span class=p>:</span> <span class=s2>&#34;&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=nt>&#34;prev_page&#34;</span><span class=p>:</span> <span class=s2>&#34;/users?limit=3&amp;cursor=&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>},</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;trace_id&#34;</span><span class=p>:</span> <span class=s2>&#34;5b427ba9ab30002d347ea17cf8000cca&#34;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p><strong>Repo Layer:</strong><br>I use raw queries for easier readability. But in reality I usually use sql builders like <code>golang squirrel</code> or <code>goqu</code>.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-go data-lang=go><span class=line><span class=cl><span class=kd>func</span> <span class=p>(</span><span class=nx>r</span> <span class=o>*</span><span class=nx>repo</span><span class=p>)</span> <span class=nf>FetchUserByUlid</span><span class=p>(</span><span class=nx>ctx</span> <span class=nx>context</span><span class=p>.</span><span class=nx>Context</span><span class=p>,</span> <span class=nx>cursorID</span> <span class=kt>string</span><span class=p>,</span> <span class=nx>limit</span> <span class=kt>uint64</span><span class=p>)</span> <span class=p>([]</span><span class=nx>entity</span><span class=p>.</span><span class=nx>User</span><span class=p>,</span> <span class=kt>error</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nx>ctx</span><span class=p>,</span> <span class=nx>cancel</span> <span class=o>:=</span> <span class=nx>context</span><span class=p>.</span><span class=nf>WithTimeout</span><span class=p>(</span><span class=nx>ctx</span><span class=p>,</span> <span class=mi>2</span><span class=o>*</span><span class=nx>time</span><span class=p>.</span><span class=nx>Second</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>defer</span> <span class=nf>cancel</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=kd>var</span> <span class=nx>sqlStatement</span> <span class=kt>string</span>
</span></span><span class=line><span class=cl>    <span class=kd>var</span> <span class=nx>args</span> <span class=p>[]</span><span class=kd>interface</span><span class=p>{}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=nx>cursorID</span> <span class=o>!=</span> <span class=s>&#34;&#34;</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=nx>sqlStatement</span> <span class=p>=</span> <span class=s>`
</span></span></span><span class=line><span class=cl><span class=s>            SELECT id, name
</span></span></span><span class=line><span class=cl><span class=s>            FROM users
</span></span></span><span class=line><span class=cl><span class=s>            WHERE id &lt; $1
</span></span></span><span class=line><span class=cl><span class=s>            ORDER BY id DESC
</span></span></span><span class=line><span class=cl><span class=s>            LIMIT $2;
</span></span></span><span class=line><span class=cl><span class=s>        `</span>
</span></span><span class=line><span class=cl>        <span class=nx>args</span> <span class=p>=</span> <span class=nb>append</span><span class=p>(</span><span class=nx>args</span><span class=p>,</span> <span class=nx>cursorID</span><span class=p>,</span> <span class=nx>limit</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span> <span class=k>else</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=nx>sqlStatement</span> <span class=p>=</span> <span class=s>`
</span></span></span><span class=line><span class=cl><span class=s>            SELECT id, name
</span></span></span><span class=line><span class=cl><span class=s>            FROM users
</span></span></span><span class=line><span class=cl><span class=s>            ORDER BY id DESC
</span></span></span><span class=line><span class=cl><span class=s>            LIMIT $1;
</span></span></span><span class=line><span class=cl><span class=s>        `</span>
</span></span><span class=line><span class=cl>        <span class=nx>args</span> <span class=p>=</span> <span class=nb>append</span><span class=p>(</span><span class=nx>args</span><span class=p>,</span> <span class=nx>limit</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1>// Execute the query</span>
</span></span><span class=line><span class=cl>    <span class=nx>rows</span><span class=p>,</span> <span class=nx>err</span> <span class=o>:=</span> <span class=nx>r</span><span class=p>.</span><span class=nx>db</span><span class=p>.</span><span class=nf>Query</span><span class=p>(</span><span class=nx>ctx</span><span class=p>,</span> <span class=nx>sqlStatement</span><span class=p>,</span> <span class=nx>args</span><span class=o>...</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=nx>err</span> <span class=o>!=</span> <span class=kc>nil</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=kc>nil</span><span class=p>,</span> <span class=nx>fmt</span><span class=p>.</span><span class=nf>Errorf</span><span class=p>(</span><span class=s>&#34;failed to execute query: %w&#34;</span><span class=p>,</span> <span class=nx>err</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=k>defer</span> <span class=nx>rows</span><span class=p>.</span><span class=nf>Close</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nx>users</span> <span class=o>:=</span> <span class=nb>make</span><span class=p>([]</span><span class=nx>entity</span><span class=p>.</span><span class=nx>User</span><span class=p>,</span> <span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1>// [SKIP] Parse the results</span>
</span></span><span class=line><span class=cl>    <span class=c1>// [SKIP] Check for errors after iterating over rows</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=nx>users</span><span class=p>,</span> <span class=kc>nil</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p><strong>Service Layer:</strong><br>At the service layer, there is logic where we have to get more data than what will be displayed to know whether the next data exists or not.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-go data-lang=go><span class=line><span class=cl><span class=kd>func</span> <span class=p>(</span><span class=nx>s</span> <span class=o>*</span><span class=nx>Service</span><span class=p>)</span> <span class=nf>FetchAllUsersWithCursor</span><span class=p>(</span><span class=nx>ctx</span> <span class=nx>context</span><span class=p>.</span><span class=nx>Context</span><span class=p>,</span> <span class=nx>cursor</span> <span class=kt>string</span><span class=p>,</span> <span class=nx>limit</span> <span class=kt>uint64</span><span class=p>)</span> <span class=p>([]</span><span class=nx>entity</span><span class=p>.</span><span class=nx>User</span><span class=p>,</span> <span class=o>*</span><span class=kt>string</span> <span class=cm>/*next cursor*/</span><span class=p>,</span> <span class=kt>error</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>// [SKIP] validation, tracer etc</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1>// Call repo layer to retrieve data</span>
</span></span><span class=line><span class=cl>    <span class=c1>// Add Limit +1 so we know if there is continuation data or not</span>
</span></span><span class=line><span class=cl>    <span class=c1>// This excess data will be discarded later</span>
</span></span><span class=line><span class=cl>    <span class=nx>results</span><span class=p>,</span> <span class=nx>err</span> <span class=o>:=</span> <span class=nx>s</span><span class=p>.</span><span class=nx>repo</span><span class=p>.</span><span class=nf>FetchUserByUlid</span><span class=p>(</span><span class=nx>ctx</span><span class=p>,</span> <span class=nx>cursor</span><span class=p>,</span> <span class=nx>limit</span><span class=o>+</span><span class=mi>1</span><span class=p>)</span> 
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=nx>err</span> <span class=o>!=</span> <span class=kc>nil</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=kc>nil</span><span class=p>,</span> <span class=kc>nil</span><span class=p>,</span> <span class=nx>fmt</span><span class=p>.</span><span class=nf>Errorf</span><span class=p>(</span><span class=s>&#34;error FetchUserByUlid: %w&#34;</span><span class=p>,</span> <span class=nx>err</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1>// Determine next cursor</span>
</span></span><span class=line><span class=cl>    <span class=kd>var</span> <span class=nx>nextCursor</span> <span class=o>*</span><span class=kt>string</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=nx>results</span><span class=p>)</span> <span class=p>&gt;</span> <span class=nb>int</span><span class=p>(</span><span class=nx>limit</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=nx>nextCursorID</span> <span class=o>:=</span> <span class=nx>results</span><span class=p>[</span><span class=nx>limit</span><span class=o>-</span><span class=mi>1</span><span class=p>].</span><span class=nx>ID</span> <span class=c1>// Set cursor if more data than limit is found</span>
</span></span><span class=line><span class=cl>        <span class=nx>nextCursor</span> <span class=p>=</span> <span class=o>&amp;</span><span class=nx>nextCursorID</span>
</span></span><span class=line><span class=cl>        <span class=nx>results</span> <span class=p>=</span> <span class=nx>results</span><span class=p>[:</span><span class=nx>limit</span><span class=p>]</span> <span class=c1>// Remove excess data</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span> <span class=k>else</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=nx>nextCursor</span> <span class=p>=</span> <span class=kc>nil</span> <span class=c1>// If there is no excess data, the next cursor is set to nil</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1>// [SKIP] Convert results</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=nx>results</span><span class=p>,</span> <span class=nx>nextCursor</span><span class=p>,</span> <span class=kc>nil</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>Assuming using Clean Architecture or Hexagonal Architecture</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>+-------------------------------------+
</span></span><span class=line><span class=cl><span class=p>|</span>            HTTP Handler             <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>    <span class=o>(</span>Handling HTTP requests and      <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>     responses, routing, etc.<span class=o>)</span>       <span class=p>|</span>
</span></span><span class=line><span class=cl>+----------------+--------------------+
</span></span><span class=line><span class=cl>                 <span class=p>|</span>
</span></span><span class=line><span class=cl>                 v
</span></span><span class=line><span class=cl>+----------------+--------------------+
</span></span><span class=line><span class=cl><span class=p>|</span>                Service              <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span> <span class=o>(</span>Business logic, orchestrating the  <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>    application flow, validation,    <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>          calling Repositories<span class=o>)</span>      <span class=p>|</span>
</span></span><span class=line><span class=cl>+----------------+--------------------+
</span></span><span class=line><span class=cl>                 <span class=p>|</span>
</span></span><span class=line><span class=cl>                 v
</span></span><span class=line><span class=cl>+----------------+--------------------+
</span></span><span class=line><span class=cl><span class=p>|</span>              Repository             <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span> <span class=o>(</span>Data access layer, interacting with<span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span>   the database, etc.<span class=o>)</span>               <span class=p>|</span>
</span></span><span class=line><span class=cl>+-------------------------------------+
</span></span></code></pre></div><p>In the code example above, the remaining layer is the HTTP Handler which serves as the View, where that layer is responsible for creating other values from the service layer process results such as temporarily storing <code>current_cursor</code>, creating <code>next_page</code> values from the FetchAllUsersWithCursor() return value and various other values for responses that require the HTTP Handler Framework.</p><p>That was an example of a simplified cursor pagination implementation so we get a little picture of its complexity. Even in the code above I intentionally skipped several things below because they are optional.</p><ul><li>Previous_Page requires implementation that is the opposite of the default SQL Query. Instead of using cursor and order default <code>WHERE id &lt; $1 ORDER BY id DESC</code>, it becomes <code>WHERE id > $1 ORDER BY id ASC</code> with cursor being the first value of the data displayed on the current page.</li><li>The possibility of cursors and orders that require 2 keys or even more.</li><li>More strict value validation for Cursor and OrderBy types.</li></ul><h3 id=benchmark>Benchmark:<a hidden class=anchor aria-hidden=true href=#benchmark>#</a></h3><figure><img src=/img/pagination/pagination-performance.webp alt="pagination performance comparison" class="clickable-image lazyload" data-src=/img/pagination/pagination-performance.webp loading=lazy></figure><p><strong>Analysis:</strong></p><ul><li>Limit-Offset Pagination has response times that start to increase significantly after page 50 (meaning at data depth 50,000), showing poor scaling for large datasets.</li><li>Limit-Offset + Query Count Pagination (run together with goroutine) Slightly slower than regular Limit-Offset, which shows additional overhead. The additional overhead from this count will be felt when requests are run in parallel. While the test above was done sequentially.</li><li>Cursor Pagination is the most efficient and stable, suitable for large datasets with many pages.</li></ul><p><strong>Notes:</strong></p><ul><li>This comparison compares all methods using uniform specifications and conditions. Network latency, structure and amount of data can affect results. So, just rely on the comparison, because the numbers will vary greatly depending on each condition.</li><li>The data used includes 100,000 user data entries that are left-joined with 2 small tables with extreme pagination trials of 1,000 entries per page.</li><li>Testing was done sequentially, page by page.</li><li>This test does not include other factors that are actually important such as memory usage, CPU, rows computed in the database.</li><li>Here I try to make minimal effort.</li><li>Theoretically alone we can actually estimate which method is superior. This benchmark confirms that.</li></ul><hr><p><code>Limit-Offset Pagination</code> has the advantage of ease of implementation, with weaknesses that will only be felt when our application reaches a level where the amount of data becomes very large. This weakness can also be overcome by providing indexed range and filtering predetermined data to users (such as when displaying bank transaction data that must determine the month).<br>On the other hand, although faster and more stable, <code>Cursor-Based Pagination</code> is slightly more complicated to implement and has certain limitations that may make it less suitable for all types of cases.</p><p>The saying <code>premature optimization is the root of all evil</code> reminds us that optimization that is too early can be a problem, but here in my personal opinion, avoiding mistakes from the start doesn&rsquo;t mean it&rsquo;s a bad thing either. In fact, making optimal architectural and design decisions, such as choosing <code>Cursor-Based Pagination</code> over <code>Limit-Offset</code>, can be considered a wise decision-making, not just premature optimization. Essentially, understanding the trade-offs of each choice and choosing the right solution for specific needs is a more appropriate approach in software development.</p></div><footer class=post-footer><ul class=post-tags><li><a href=http://localhost:1313/tags/golang/>Golang</a></li><li><a href=http://localhost:1313/tags/database/>Database</a></li><li><a href=http://localhost:1313/tags/optimization/>Optimization</a></li><li><a href=http://localhost:1313/tags/best-practices/>Best Practices</a></li></ul><nav class=paginav><a class=prev href=http://localhost:1313/post/db-transaction/><span class=title>« Prev</span><br><span>Teknik Implementasi Database Transaction pada Logic Layer di Backend Golang</span>
</a><a class=next href=http://localhost:1313/post/structuring-project-folder/><span class=title>Next »</span><br><span>Struktur Folder dan Aturan Penulisan Kode dalam Project Golang: Preferensi Pribadi</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share Pagination Optimization: Why Limit-Offset Can Be a Time Bomb and Cursor Pagination as the Solution on x" href="https://x.com/intent/tweet/?text=Pagination%20Optimization%3a%20Why%20Limit-Offset%20Can%20Be%20a%20Time%20Bomb%20and%20Cursor%20Pagination%20as%20the%20Solution&amp;url=http%3a%2f%2flocalhost%3a1313%2fpost%2fpagination%2f&amp;hashtags=Golang%2cDatabase%2cOptimization%2cBestPractices"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Pagination Optimization: Why Limit-Offset Can Be a Time Bomb and Cursor Pagination as the Solution on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http%3a%2f%2flocalhost%3a1313%2fpost%2fpagination%2f&amp;title=Pagination%20Optimization%3a%20Why%20Limit-Offset%20Can%20Be%20a%20Time%20Bomb%20and%20Cursor%20Pagination%20as%20the%20Solution&amp;summary=Pagination%20Optimization%3a%20Why%20Limit-Offset%20Can%20Be%20a%20Time%20Bomb%20and%20Cursor%20Pagination%20as%20the%20Solution&amp;source=http%3a%2f%2flocalhost%3a1313%2fpost%2fpagination%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Pagination Optimization: Why Limit-Offset Can Be a Time Bomb and Cursor Pagination as the Solution on facebook" href="https://facebook.com/sharer/sharer.php?u=http%3a%2f%2flocalhost%3a1313%2fpost%2fpagination%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Pagination Optimization: Why Limit-Offset Can Be a Time Bomb and Cursor Pagination as the Solution on whatsapp" href="https://api.whatsapp.com/send?text=Pagination%20Optimization%3a%20Why%20Limit-Offset%20Can%20Be%20a%20Time%20Bomb%20and%20Cursor%20Pagination%20as%20the%20Solution%20-%20http%3a%2f%2flocalhost%3a1313%2fpost%2fpagination%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Pagination Optimization: Why Limit-Offset Can Be a Time Bomb and Cursor Pagination as the Solution on telegram" href="https://telegram.me/share/url?text=Pagination%20Optimization%3a%20Why%20Limit-Offset%20Can%20Be%20a%20Time%20Bomb%20and%20Cursor%20Pagination%20as%20the%20Solution&amp;url=http%3a%2f%2flocalhost%3a1313%2fpost%2fpagination%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentColor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li></ul></footer><script src=https://giscus.app/client.js data-repo=muchlist/paper data-repo-id=R_kgDOMD4syA data-category=General data-category-id=DIC_kwDOMD4syM4ChOKX data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=top data-theme=dark_dimmed data-lang=id data-loading=lazy crossorigin=anonymous async></script></article></main><footer class=footer><span>&copy; 2025 <a href=http://localhost:1313/>Muchlis Dev</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>