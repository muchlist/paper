[{"content":"Dalam pengembangan Aplikasi Golang, sering kali kita temukan satu struct object yang dipakai untuk berbagai keperluan, seperti representasi data di database sekaligus payload dalam request dan response API. Meskipun terlihat praktis, pendekatan ini sebenarnya dapat memunculkan masalah terkait keamanan dan pemeliharaan. Artikel ini akan membahas pentingnya memisahkan DTO, Entity dan Model dengan menerapkan sedikit prinsip Domain-Driven Design (DDD).\nMemahami Entity, Model dan DTO dalam Prinsip Domain-Driven Design Domain-Driven Design (DDD) adalah metodologi pengembangan perangkat lunak yang berfokus pada pemisahan tanggung jawab melalui pemodelan yang berorientasi pada domain bisnis. Dalam DDD, kita mengenal beberapa konsep penting:\nData Transfer Object (DTO) : Digunakan untuk mengirimkan data antar fungsi tanpa melibatkan logika bisnis yang kompleks. Misalnya, struct untuk request, response, dan parameter fungsi. Entity : Digunakan untuk menyimpan data yang akan digunakan dalam logika aplikasi. Sebuah struct disebut entity jika memiliki identitas (seperti ID) yang membedakannya dari data lain. Entity dapat memiliki logika sendiri. Misalnya, entitas Weather yang memiliki metode IsOutdoorEventFeasible() untuk mengevaluasi apakah cuaca cocok untuk acara luar ruang. type WeatherEntity struct { ID string // misal : Kombinasi Kode Lokasi dan Timestamp City string Temperature float64 Humidity int Description string } // IsOutdoorEventFeasible mengevaluasi apakah cuaca cocok untuk acara luar ruang. func (w *WeatherEntity) IsOutdoorEventFeasible() bool { // acara luar ruang dianggap tidak layak jika: // - Suhu di bawah 15 derajat Celsius atau di atas 35 derajat Celsius // - Deskripsi cuaca mengindikasikan hujan atau badai if w.Temperature \u0026lt; 15 || w.Temperature \u0026gt; 35 { return false } if w.Description == \u0026#34;rain\u0026#34; || w.Description == \u0026#34;storm\u0026#34; { return false } return true } Repository : Object Repository menyembunyikan detail implementasi penyimpanan data. Sedangkan Struct Model berfungsi sebagai representasi data pada database yang digunakan oleh Repository. Application Service : Menangani logika bisnis yang memerlukan interaksi dengan komponen eksternal atau layanan lainnya, dalam clean architecture ini sering disebut usecase atau service. Menghandle operasi-operasi yang tidak secara alami cocok dalam konteks Entity atau Value Object. Sebenarnya masih banyak yang lain, Misalnya Value Object, Aggregate, Domain-Service dll. Namun kita ingin agar code kita menjadi \u0026ldquo;cukup-baik untuk maintainability\u0026rdquo;, tetapi juga \u0026ldquo;tidak menjadi terlalu rumit\u0026rdquo;, jadi disini kita agak sedikit longgar dalam penerapan DDD tersebut.\nMengapa Pemisahan itu Penting? Menggunakan struct yang sama di berbagai lapisan aplikasi (database, logika bisnis, presentasi) dapat menciptakan keterikatan yang tinggi. Ini berarti perubahan di satu area, seperti database, dapat mempengaruhi area lain, seperti API. Misalnya, menambahkan kolom baru di database yang tidak relevan untuk pengguna API tetapi diperlukan untuk proses internal dapat menyebabkan perluasan struct yang tidak perlu dan bahkan mengacaukan logika aplikasi.\nSkenario Misalkan kita memiliki aplikasi yang membantu pengguna merencanakan acara berdasarkan prakiraan cuaca. Aplikasi kita menggunakan API cuaca pihak ketiga untuk mendapatkan informasi cuaca terkini.\ntype Weather struct { City string `json:\u0026#34;city\u0026#34; db:\u0026#34;city\u0026#34;` Temperature float64 `json:\u0026#34;temperature\u0026#34; db:\u0026#34;temperature\u0026#34;` Humidity int `json:\u0026#34;humidity\u0026#34; db:\u0026#34;humidity\u0026#34;` WindSpeed float64 `json:\u0026#34;wind_speed\u0026#34; db:\u0026#34;wind_speed\u0026#34;` Description string `json:\u0026#34;description\u0026#34; db:\u0026#34;description\u0026#34;` } Suatu hari, API cuaca pihak ketiga mengumumkan perubahan pada respons mereka, menambahkan lebih banyak detail seperti airQualityIndex, visibility, dan uvIndex. Bahkan melakukan perubahan major ke versi 2 seperti split temperatur menjadi temperature_celcius dan temperature_kelvin.\nDampak Tanpa Pemisahan Struct (bad) Jika kita menggunakan Weather struct yang sama untuk menangkap respons dari API, menyimpan data di database, dan juga sebagai respons API kita, perubahan pada API pihak ketiga dapat menyebabkan beberapa masalah berikut:\nPerubahan di Banyak Tempat: Perubahan di suatu struct artinya juga mengubah database, logika bisnis, dan mungkin juga data yang dikonsumsi oleh frontend. Overfetching and Irrelevant Data: kita mungkin tidak memerlukan semua data tambahan seperti temperature_kelvin atau uvIndex untuk tujuan aplikasi kita, tetapi karena menggunakan struktur yang sama, kita terpaksa menangani data ekstra ini. Peningkatan Kompleksitas: Dengan adanya data baru, kita mungkin memerlukan sedikit modifikasi pada tipe datanya untuk menyesuaikan Tag, Marshaler, Scanners and Valuers. Dampak Dengan Pemisahan Struct (good) Sebaliknya, dengan memisahkan DTO, Entity, dan Model, kita dapat lebih efisien dalam menangani perubahan ini.\nDTO (Data Transfer Object):\nkita membuat struct khusus untuk menangkap respons dari API cuaca yang mencakup semua data baru (atau hanya data relevan). Membantu kita untuk mengetahui ketersediaan data dari API.\nTerhadap skenario diatas, kita cukup menyesuaikan dibagian layer API Client saja.\ntype WeatherAPIResponse struct { City string `json:\u0026#34;city\u0026#34;` TemperatureCelcius float64 `json:\u0026#34;temperature_celcius\u0026#34;` TemperatureKelvin float64 `json:\u0026#34;temperature_kelvin\u0026#34;` Humidity int `json:\u0026#34;humidity\u0026#34;` WindSpeed float64 `json:\u0026#34;wind_speed\u0026#34;` Description string `json:\u0026#34;description\u0026#34;` AirQualityIndex int `json:\u0026#34;airQualityIndex\u0026#34;` Visibility int `json:\u0026#34;visibility\u0026#34;` UvIndex int `json:\u0026#34;uvIndex\u0026#34;` } func (w *WeatherAPIResponse) ToEntity(){ // transform } Entity:\nEntity Weather dalam aplikasi kita hanya menyimpan data yang relevan untuk fungsi aplikasi, seperti Temperature, Humidity, dan Description. Tidak perlu menyimpan uvIndex atau visibility jika data tersebut tidak digunakan dalam proses perencanaan acara, dengan begitu kita mengetahui data mana yang penting untuk logic dan yang tidak.\ntype WeatherEntity struct { ID string // Kombinasi Kode Lokasi dan Timestamp City string Temperature float64 Humidity int Description string } // IsOutdoorEventFeasible mengevaluasi apakah cuaca cocok untuk acara luar ruang. func (w *WeatherEntity) IsOutdoorEventFeasible() bool { // acara luar ruang dianggap tidak layak jika: // - Suhu di bawah 15 derajat Celsius atau di atas 35 derajat Celsius // - Deskripsi cuaca mengindikasikan hujan atau badai if w.Temperature \u0026lt; 15 || w.Temperature \u0026gt; 35 { return false } if w.Description == \u0026#34;rain\u0026#34; || w.Description == \u0026#34;storm\u0026#34; { return false } return true } Logika Bisnis (Usecase Layer):\nLogika bisnis seharusnya tidak mengenal model database atau response dari API pihak ketiga. Logika bisnis hanya mengolah data yang sudah berupa Entity atau yang kita bisa kontrol kestabilannya. Ini memudahkan pemeliharaan dan mengurangi risiko error.\nModel Database:\nUntuk keperluan menyimpan ke database gunakan struct tersendiri, khususnya jika menggunkan ORM\ntype WeatherModel struct { ID string `db:\u0026#34;id\u0026#34;` City string `db:\u0026#34;city\u0026#34;` Temperature float64 `db:\u0026#34;temperature\u0026#34;` Humidity int `db:\u0026#34;humidity\u0026#34;` Description string `db:\u0026#34;description\u0026#34;` } func (w *WeatherModel) ToEntity(){ // transform } func FromEntity(WeatherEntity) WeatherModel { // transform } dan seterusnya untuk WeatherRequestDTO dan WeatherResponseDTO.\nTrade-offs Meskipun pemisahan struktur data seperti DTO (Data Transfer Object), Entity, dan Model database memiliki manfaat jangka panjang seperti keamanan, kemudahan dalam testing, dan separation of concern yang jelas, ada beberapa kekurangan yang perlu dipertimbangkan juga. Salah satu kekurangan utamanya adalah kebutuhan untuk melakukan transformasi antara struct-struct ini, yang berarti ada sedikit pengorbanan kecepatan.\nNamun, pendekatan ini sering dianggap sebagai bayaran-yang-wajar untuk manfaat yang diperoleh. Buku-buku populer seperti Clean Code oleh Robert C. Martin, The Pragmatic Programmer oleh Andrew Hunt dan David Thomas, serta Refactoring: Improving the Design of Existing Code oleh Martin Fowler, sering kali menekankan pentingnya memprioritaskan kode yang benar dan mudah dipelihara sebelum fokus pada kecepatan.\nLagipula, latensi yang dihasilkan dari transformasi data ini sangat sangat sangat minim jika dibandingkan dengan latensi operasi database, yang cenderung menjadi bottleneck yang lebih signifikan dalam banyak aplikasi.\nKapan Sebaiknya Tidak Memisahkan Struct? Sistemnya terlalu sederhana. Memerlukan kecepatan tinggi seperti dalam pengembangan game. Peningkatan peforma sekecil-kecilnya dinilai lebih penting daripada keterbacaan dan kemudahan pemeliharaan. Cara Memisahkan Struct yang tepat Saya menyarankan pendekatan berikut untuk memisahkan struct golang dalam arsitektur API. Pendekatan ini memastikan bahwa setiap lapisan dalam aplikasi memiliki tanggung jawab yang jelas dan terpisah, sehingga memudahkan pemeliharaan dan pengembangan di masa mendatang.\nStruct untuk Lapisan Presentation: WeatherRequest dan WeatherResponse: Struct ini digunakan untuk menangani data yang masuk dan keluar dari API (presentation). Mereka bertanggung jawab untuk memvalidasi dan memformat data sesuai dengan kebutuhan klien. Untuk kasus yang lebih kompleks, seperti fitur partial update, Kamu mungkin memerlukan WeatherUpdateRequest. Versi ini menggunakan field pointer untuk memungkinkan pembaruan sebagian (partial update). Struct untuk Lapisan Domain: WeatherEntity: Entity ini mewakili data dalam domain bisnis dan berisi logika yang terkait langsung dengan aturan bisnis. Entity harus stabil dan tidak terpengaruh oleh perubahan di lapisan lain, seperti database atau API eksternal. Untuk kasus yang lebih kompleks, seperti fitur partial update, Kamu mungkin memerlukan WeatherUpdateDTO. Versi DTO yang juga menggunakan field pointer untuk fleksibilitas dalam pengiriman data. Struct untuk Lapisan Persistence: WeatherModel: Struct ini digunakan untuk interaksi dengan database. Model ini mencerminkan skema penyimpanan dan dapat berubah seiring dengan perubahan di layer database. Diagram Implementasi Dengan asumsi menggunakan Clean Architecture atau Hexagonal Architecture, maka :\nHandler Layer mengelola data request dan response, mengubah request ke tipe data internal yang dapat kita kontrol sepenuhnya (entity) sebelum diteruskan ke Usecase. Usecase Layer bekerja dengan entity yang stabil, layer ini seharusnya menghindari ketergantungan langsung pada model database atau format API eksternal. Repository Layer mengelola akses ke database dan mengubah data ke dan dari entity yang digunakan oleh usecase. Pendekatan ini memastikan bahwa setiap lapisan terisolasi dari perubahan yang tidak relevan di lapisan lain, sehingga meningkatkan ketahanan dan fleksibilitas aplikasi. Dengan memisahkan tanggung jawab di setiap layer, aplikasi menjadi lebih modular, memudahkan pemeliharaan dan skalabilitas.\nKesimpulan Mengimplementasikan pemisahan struct DTO, Entity dan Model dalam desain API menggunakan Golang merupakan investasi kecil yang bisa menghemat banyak waktu dan sumber daya untuk pengembangan dan pemeliharaan di masa depan, membuat sistem kita tidak hanya efisien tapi juga mudah untuk dikelola dan dikembangkan. Pendekatan ini dapat membagi tanggung jawab tiap komponen secara jelas, mengurangi ketergantungan antar-modul, dan pada akhirnya menguatkan keseluruhan arsitektur aplikasi itu sendiri.\nTentu, tidak ada satu pendekatan yang sempurna untuk setiap situasi. Bagaimana pengalamanmu dalam mengimplementasikan atau mungkin tidak mengimplementasikan prinsip ini? Apakah ada kasus khusus di mana kamu menemukan alternatif yang lebih efektif? Mari berbagi pengalaman di kolom komentar.\n","permalink":"https://blog.muchlis.dev/post/struct-separation/","summary":"\u003cp\u003eDalam pengembangan Aplikasi Golang, sering kali kita temukan satu struct object yang dipakai untuk berbagai keperluan,\nseperti representasi data di database sekaligus payload dalam request dan response API.\nMeskipun terlihat praktis, pendekatan ini sebenarnya dapat memunculkan masalah terkait keamanan dan pemeliharaan.\nArtikel ini akan membahas pentingnya memisahkan DTO, Entity dan Model dengan menerapkan sedikit prinsip Domain-Driven Design (DDD).\u003c/p\u003e","title":"Memahami Pentingnya Memisahkan DTO, Entity dan Model dalam Pengembangan Aplikasi"},{"content":"Database transaction adalah aspek krusial dalam pengembangan aplikasi, terutama pada proyek yang menuntut konsistensi data yang tinggi. Artikel ini akan membahas bagaimana cara melakukan transaksi-database pada service layer (logic), dengan tetap mempertahankan prinsip-prinsip clean architecture dan separation of concerns.\nArsitektur terhadap Database Transaction Dalam arsitektur populer seperti Clean Architecture, Hexagonal Architecture, maupun pendekatan Domain-Driven Design (DDD), pemisahan tanggung jawab menjadi kunci utama. Kita umumnya membagi kode menjadi beberapa lapisan, misalnya Handler -\u0026gt; Service -\u0026gt; Repository. Lapisan service idealnya berisi logika bisnis murni tanpa bergantung pada library eksternal, sementara repository bertanggung jawab atas interaksi dengan database.\nNamun, ketika mengimplementasikan operasi database yang memenuhi prinsip ACID (Atomicity, Consistency, Isolation, Durability), muncul pertanyaan: di mana sebaiknya logika database-transaction ditempatkan? Di lapisan logika atau di lapisan repository? Hal ini seringkali menjadi dilema para programmer, terutama karena tantangan yang muncul dari prinsip arsitektur yang mendesak pemecahan akses ke datastore melalui berbagai repository yang kecil-kecil dan termodularisasi.\nnote : Atomicity artinya Menjamin bahwa serangkaian operasi dalam satu transaksi harus sepenuhnya berhasil atau sepenuhnya gagal.\nSebagai ilustrasi, mari kita tinjau kasus transfer uang antar rekening: \u0026ldquo;Transfer uang dari rekening A ke rekening B, perbarui semua data terkait, dan jika gagal, batalkan seluruh proses.\u0026rdquo; Terdapat dua pendekatan umum:\nPendekatan A : Logika Transaksi di Repository Pendekatan ini sederhana karena transaksi dimulai dan dikelola langsung di lapisan repository. Namun, pendekatan ini memiliki kelemahan: logika bisnis (transfer uang) tercampur dengan logika akses data. Bayangkan jika ada kebutuhan tambahan, seperti mengirim event saldo ke pihak ketiga sebagai bagian dari atomicity transaksi. Apakah repository harus memiliki dependensi ke layanan eksternal juga? Hal ini jelas melanggar prinsip separation of concerns. Selain itu, service layer menjadi sangat tipis, sehingga menghilangkan manfaat unit test pada layer tersebut.\nPendekatan B : Logika Transaksi di Service Pendekatan ini menempatkan logika transaksi di service layer, sesuai dengan prinsip separation of concerns. Namun, implementasinya lebih menantang. Bagaimana caranya agar service layer tetap independen dari library database, seperti GORM, sambil tetap bisa mengelola transaksi?\nJadi, Di mana sebaiknya logika transaksi ditempatkan? Di lapisan logika atau di lapisan repository? Jawabannya adalah di lapisan logika. Hal ini berlaku baik ketika proses mutasi yang melibatkan interaksi dengan beberapa sumber data, maupun ketika melakukan pengumpulan data (agregasi). Alasannya adalah karena logika bisnislah yang menentukan keadaan valid dari suatu kumpulan data pada waktu tertentu. Dengan kata lain, jika sebuah agregat tidak disimpan dalam keadaan yang utuh dan valid, maka operasi bisnis yang dilakukan akan dianggap tidak sesuai dengan aturan bisnis yang berlaku.\nHal diatas juga sejalan dengan penuturan pada buku DDD yang pernah saya baca. Domain Driven Design\nTantangan dan Solusi Menjaga agar lapisan service tetap murni dari ketergantungan pihak ketiga sambil mengelola transaksi database yang kompleks memang sulit. Namun, beberapa teknik dapat diterapkan untuk mengatasi masalah ini, seperti menggunakan abstraksi transaksi di service tanpa harus berurusan langsung dengan implementasi transaksi dari library database.\nUntuk menjaga kemurnian service layer dan tetap mengelola transaksi database dengan efektif, kita akan menggunakan pendekatan berlapis dengan beberapa komponen kunci:\n1. DBTX interface Mendefinisikan interface yang mengabstraksi operasi database, baik operasi biasa maupun operasi dalam transaksi. Ini memungkinkan service layer untuk berinteraksi dengan database tanpa bergantung pada implementasi spesifik. Interface ini akan mencakup method-method seperti Exec, Query, QueryRow, Begin, Commit, Rollback, dan lainnya yang dibutuhkan. Kabar baiknya, jika kamu menggunakan gorm, hal ini tidak perlu dilakukan karena gorm sudah melakukannya (menggabungkan kedua method tersebut menjadi 1). Disini saya membuat contoh dengan menggunakan pgx.\npackage dbtx import ( \u0026#34;github.com/jackc/pgx/v5\u0026#34; \u0026#34;github.com/jackc/pgx/v5/pgconn\u0026#34; \u0026#34;github.com/jackc/pgx/v5/pgxpool\u0026#34; ) type DBTX interface { // method ini digunakan pgx untuk operasi biasa Prepare(ctx context.Context, name, sql string) (*pgconn.StatementDescription, error) Exec(ctx context.Context, sql string, arguments ...interface{}) (commandTag pgconn.CommandTag, err error) Query(ctx context.Context, sql string, args ...interface{}) (pgx.Rows, error) QueryRow(ctx context.Context, sql string, args ...interface{}) pgx.Row // method ini digunakan pgx untuk operasi transaction Begin(ctx context.Context) (pgx.Tx, error) Commit(ctx context.Context) error Rollback(ctx context.Context) error // DBTX menggabungkan keduanya... } 2. PGStore Menyediakan implementasi konkret dari interface DBTX untuk library pgx. Struktur ini akan menangani pemilihan antara koneksi database biasa atau koneksi transaksi. PGStore akan memeriksa apakah context berisi transaksi yang aktif (pgx.Tx). Jika ada, operasi database akan dilakukan menggunakan transaksi tersebut. Jika tidak, operasi akan dilakukan menggunakan koneksi pool pgxpool.\nNewPGStore berfungsi untuk membuat instance PGStore. Fungsi ini menerima koneksi pool pgxpool dan (opsional) objek transaksi pgx.Tx. Hal ini akan memudahkan pembuatan instance PGStore dengan cara yang konsisten dan terkontrol.\ntype PGStore struct { NonTX *pgxpool.Pool Tx pgx.Tx } // NewPGStore return interface can execute TX and pgx.Pool func NewPGStore(pool *pgxpool.Pool, tx pgx.Tx) DBTX { var pgstore PGStore if tx != nil { pgstore.Tx = tx return \u0026amp;pgstore } pgstore.NonTX = pool return \u0026amp;pgstore } // Begin implements DBTX func (p *PGStore) Begin(ctx context.Context) (pgx.Tx, error) { if p.Tx != nil { return nil, errors.New(\u0026#34;cannot begin inside running transaction\u0026#34;) } return p.NonTX.Begin(ctx) } // Commit implements DBTX func (p *PGStore) Commit(ctx context.Context) error { if p.Tx != nil { return p.Tx.Commit(ctx) } return errors.New(\u0026#34;cannot commit: nil tx value\u0026#34;) } // Rollback implements DBTX func (p *PGStore) Rollback(ctx context.Context) error { if p.Tx != nil { return p.Tx.Rollback(ctx) } return errors.New(\u0026#34;cannot roleback: nil tx value\u0026#34;) } // Exec implements DBTX func (p *PGStore) Exec(ctx context.Context, sql string, arguments ...interface{}) (commandTag pgconn.CommandTag, err error) { if p.Tx != nil { return p.Tx.Exec(ctx, sql, arguments...) } return p.NonTX.Exec(ctx, sql, arguments...) } // Prepare implements DBTX func (p *PGStore) Prepare(ctx context.Context, name string, sql string) (*pgconn.StatementDescription, error) { if p.Tx != nil { return p.Tx.Prepare(ctx, name, sql) } return nil, errors.New(\u0026#34;cannot prefare: pool does not have prefare method\u0026#34;) } // Query implements DBTX func (p *PGStore) Query(ctx context.Context, sql string, args ...interface{}) (pgx.Rows, error) { if p.Tx != nil { return p.Tx.Query(ctx, sql, args...) } return p.NonTX.Query(ctx, sql, args...) } // QueryRow implements DBTX func (p *PGStore) QueryRow(ctx context.Context, sql string, args ...interface{}) pgx.Row { if p.Tx != nil { return p.Tx.QueryRow(ctx, sql, args...) } return p.NonTX.QueryRow(ctx, sql, args...) } 3. Fungsi ExtractTx dan injectTx Selanjutnya kita buat helper yang mengotomasi penggunaan NewPGStore ini. ExtractTx digunakan untuk mengekstraksi koneksi database transaction yang disimpan pada context injectTx digunakan untuk hal yang sebaliknya, yaitu menginjeksi database transaction ke context.\npackage dbtx import ( \u0026#34;github.com/jackc/pgx/v5\u0026#34; \u0026#34;github.com/jackc/pgx/v5/pgxpool\u0026#34; ) type KeyTransaction string const TXKey KeyTransaction = \u0026#34;unique-key-transaction\u0026#34; // ExtractTx extract transaction from context and transform database into dbtx.DBTX func ExtractTx(ctx context.Context, defaultPool *pgxpool.Pool) DBTX { tx, ok := ctx.Value(TXKey).(pgx.Tx) if !ok || tx == nil { return NewPGStore(defaultPool, nil) } return NewPGStore(nil, tx) } // injectTx injects transaction to context func injectTx(ctx context.Context, tx pgx.Tx) context.Context { return context.WithValue(ctx, TXKey, tx) } 4. TxManager dan fungsi WithAtomic WithAtomic mengotomasi penggunaan ExtractTx dan injectTx ini. Merupakan wrapper function yang apabila gagal akan melakukan ROLEBACK, dan apabila berhasil akan melakukan COMMIT database transaction.\nSingkatnya, ketika WithAtomic dipanggil, context akan terisi dengan database transaction, selanjutnya context berisi database transaction itu yang akan dipakai untuk menjalankan operasi-operasi database berikutnya, repository otomatis akan menggunakannya transaction ini karena melakukan ExtractTx setiap kali perintah database dieksekusi.\npada layer logika kita hanya berurusan dengan WithAtomic ini.\npackage dbtx import ( \u0026#34;log/slog\u0026#34; \u0026#34;github.com/jackc/pgx/v5/pgxpool\u0026#34; ) type TxManager interface { WithAtomic(ctx context.Context, tFunc func(ctx context.Context) error) error } type txManager struct { db *pgxpool.Pool log *slog.Logger } func NewTxManager(sqlDB *pgxpool.Pool, log *slog.Logger) TxManager { return \u0026amp;txManager{ db: sqlDB, log: log, } } // ========================================================================= // TRANSACTION // WithAtomic runs function within transaction // The transaction commits when function were finished without error func (r *txManager) WithAtomic(ctx context.Context, tFunc func(ctx context.Context) error) error { // begin transaction tx, err := r.db.Begin(ctx) if err != nil { return fmt.Errorf(\u0026#34;begin transaction: %w\u0026#34;, err) } // run callback err = tFunc(injectTx(ctx, tx)) if err != nil { // if error, rollback if errRollback := tx.Rollback(ctx); errRollback != nil { r.log.Error(\u0026#34;rollback transaction\u0026#34;, slog.String(\u0026#34;error\u0026#34;, errRollback.Error())) } return err } // if no error, commit if errCommit := tx.Commit(ctx); errCommit != nil { return fmt.Errorf(\u0026#34;failed to commit transaction: %w\u0026#34;, errCommit) } return nil } 5. Implementasi WithAtomic dan ExtractTx Service Layer: Service layer menggunakan TxManager.WithAtomic untuk membungkus logika bisnis dalam transaksi. Ini memastikan bahwa semua operasi database dalam logika bisnis tersebut dilakukan secara atomik.\nRepository Layer: Repository layer menggunakan ExtractTx untuk mendapatkan objek DBTX yang tepat (berbasis transaksi atau koneksi biasa) dari context. Semua operasi database di repository dilakukan melalui objek DBTX ini.\nSehingga codenya akan kurang lebih menjadi seperti berikut.\ntype service struct { Repo AccountStorer TxManager TxManager // helper untuk transaction menjadi dependecy tambahan atau bisa digabung ke repo } func (s *service) TransferMoney(ctx context.Context, input model.TransferDTO) error { // shared variable untuk menampung hasil didalam WithAtomic jika ada // result := ... // Membungkus prosesnya dengan database transaction txErr := s.TxManager.WithAtomic(ctx, func(ctx context.Context) error { // Mengambil account A accountA, err := s.Repo.GetAccountByID(ctx, input.AccountA) if err != nil { return err // Gagal mengambil account A } // Mengambil account B accountB, err := s.Repo.GetAccountByID(ctx, input.AccountB) if err != nil { return err // Gagal mengambil account B } // Memeriksa apakah saldo account A cukup if accountA.Balance \u0026lt; input.Amount { return errors.New(\u0026#34;saldo tidak cukup\u0026#34;) // Gagal karena saldo tidak cukup } // Mengurangi saldo account A accountA.Balance -= input.Amount if err := s.Repo.UpdateAccount(ctx, accountA); err != nil { return err // Gagal update saldo account A } // Menambahkan jumlah ke saldo account B accountB.Balance += input.Amount if err := s.Repo.UpdateAccount(ctx, accountB); err != nil { return err // Gagal update saldo account B } return nil }) if txErr != nil { return txErr } return nil } // Mengambil account berdasarkan ID func (r *repo) GetAccountByID(ctx context.Context, id uint) (model.AccountEntity, error) { dbtx := ExtractTx(ctx, r.db) // mengekstraksi context dan menjadikan db biasa menjadi DBTX interface var account model.AccountModel err := dbtx.QueryRow(ctx, \u0026#34;SELECT * FROM accounts WHERE id = $1\u0026#34;, id).Scan( /* ...scan fields of account... */ ) return account, err } // Mengupdate account func (r *repo) UpdateAccount(ctx context.Context, account model.AccountEntity) error { dbtx := ExtractTx(ctx, r.db) // mengekstraksi context dan menjadikan db biasa menjadi DBTX interface _, err := dbtx.Exec(ctx, ` UPDATE accounts SET balance = $1 WHERE id = $2`, account.Balance, account.ID) return err } Dengan mengimplementasikan cara diatas, kita berhasil memisahkan lapisan logika dari ketergantungan pada library pihak ketiga. Pada contoh repository yang saya sertakan, dapat dilihat bahwa untuk mengganti ORM pun, service layer tidak memerlukan perubahan apapun. YEYY.\nMari kita jabarkan lagi, apa saja keuntungannya :\nLogic layer tetap murni, tidak tercemar oleh package gorm atau driver lainnya. Transaksi database dapat dikendalikan dengan efektif, memungkinkan untuk mengatur scope transaksi dijaga sekecil mungkin jika diperlukan. Pendekatan ini berbeda dengan penerapan transaksi dalam middleware, yang dapat menyebabkan seluruh proses logika berada dalam satu transaksi database. Readability kode tetap terjaga. Unit testing tetap berfokus pada logika bisnis saja. Sample Github Repository Saya menyertakan contoh kode dalam dua versi, satu untuk GORM dan satu lagi untuk implementasi lainnya (pgx). Di sini, GORM lebih simple karena secara dasar GORM telah menggabungkan operasi database biasa dengan operasi database transaction.\nBerikut ini repositorynya : REPOSITORY\nDalam menerapkan transaksi database, penting juga untuk mempertimbangkan kemungkinan terjadinya deadlock. Dalam contoh kode yang saya berikan di atas, saya telah menyederhanakan kode dengan mengesampingkan aspek-aspek tersebut. Saya akan membahas tentang deadlock lebih lanjut dalam kesempatan berikutnya.\n","permalink":"https://blog.muchlis.dev/post/db-transaction/","summary":"\u003cp\u003eDatabase transaction adalah aspek krusial dalam pengembangan aplikasi, terutama pada proyek yang menuntut konsistensi data yang tinggi. Artikel ini akan membahas bagaimana cara melakukan transaksi-database pada service layer (logic), dengan tetap mempertahankan prinsip-prinsip clean architecture dan separation of concerns.\u003c/p\u003e","title":"Teknik Implementasi Database Transaction pada Logic Layer di Backend Golang"},{"content":"Pagination adalah teknik dalam membagi hasil query database menjadi bagian-bagian yang lebih kecil. Menggunakan Query LIMIT OFFSET adalah metode yang paling umum digunakan. Namun, metode ini ternyata memiliki beberapa kelemahan, terutama dalam hal performa pada dataset yang sangat besar. Artikel ini akan membahas masalah-masalah yang akan muncul saat menggunakan LIMIT OFFSET dan mengeksplorasi alternatif yang lebih efisien, seperti cursor-based pagination dan seek method.\nPentingnya Pagination dan Tantangannya Pagination memiliki beberapa manfaat, seperti:\nMenjaga Performance: Mengembalikan data yang besar sekaligus itu lambat dan memakan banyak sumber daya. Dengan membagi data menjadi potongan-potongan yang lebih kecil, API bisa mengembalikan data lebih cepat dan dengan sumber daya yang lebih sedikit. Memproses data yang besar juga memerlukan banyak memori, yang bisa menjadi masalah untuk perangkat dengan sumber daya terbatas seperti ponsel. Dengan menggunakan pagination, API dapat membatasi jumlah data yang perlu disimpan dalam memori pada suatu waktu.\nUser Experience: Untuk aplikasi klien yang menampilkan data kepada user, pagination dapat meningkatkan pengalaman user dengan menyediakan antarmuka yang lebih cepat dan responsif. User dapat melihat hasil awal dengan cepat dan dapat meminta data tambahan sesuai kebutuhan.\nNamun, penting untuk diingat bahwa pagination tidak selalu menjadi solusi yang sempurna. Pada dataset yang sangat besar, teknik pagination dapat menghadapi tantangan yang akan menjadi sangat fatal dikemudian hari.\nLIMIT OFFSET Pagination Disini kita akan bahas kekurangan dari cara pagination menggunakan LIMIT OFFSET dan bagaimana cara meminimalisir kekurangan tersebut.\nMengapa LIMIT OFFSET Lambat untuk Dataset yang Besar? Saat berhadapan dengan dataset yang sangat besar, pagination menggunakan LIMIT OFFSET seringkali mengalami penurunan performa. Ini karena setiap kali kita meminta halaman baru, database harus memindai seluruh tabel dari awal untuk menemukan data yang sesuai, meskipun kita hanya membutuhkan sebagian kecil data.\nBerikut adalah contoh query SQL yang menunjukkan bagaimana LIMIT dan OFFSET diterapkan:\nSELECT * FROM records ORDER BY id LIMIT 10 OFFSET 1000; Penjelasan:\nLIMIT menentukan jumlah maksimal baris yang dikembalikan.\nOFFSET menentukan berapa banyak baris yang harus skip sebelum mulai mengembalikan hasil.\nPada contoh di atas, query tersebut sebenarnya akan memindai 1000 baris pertama, membuang data yang tidak diperlukan, dan mengembalikan 10 baris berikutnya. Jika tabel memiliki jutaan baris, melewati sejumlah besar baris dengan offset yang besar akan membuat query berjalan lebih lambat karena database harus mengurutkan dan memindai semua baris tersebut sebelum mengembalikan hasil.\nArtinya jika klien melakukan permintaaan page 2, page 3 dan seterusnya maka akan menyebabkan database harus memproses berkali-kali lipat data dibandingkan dengan jumlah yang sebenarnya dikembalikan kepada klien.\nSebagai ilustrasi, asumsi jika 1 halaman menampilkan 100 data:\nUntuk page 1: OFFSET 0, LIMIT 100 -\u0026gt; memindai dan mengembalikan 100 baris. Untuk page 2: OFFSET 100, LIMIT 100 -\u0026gt; memindai dan membuang 100 baris, kemudian memindai dan mengembalikan 100 baris berikutnya. Untuk page 3: OFFSET 200, LIMIT 100 -\u0026gt; memindai dan membuang 200 baris, kemudian memindai dan mengembalikan 100 baris berikutnya. Untuk page 100: OFFSET 10000, LIMIT 100 -\u0026gt; memindai dan membuang 10000 baris, kemudian memindai dan mengembalikan 100 baris berikutnya. Semakin besar nilai offset, semakin banyak baris yang perlu dipindai dan dibuang, yang membuat query semakin lambat dan tidak efisien. Ini menjadi sangat buruk untuk tabel dengan jutaan baris karena memproses dan membuang banyak data setiap kali ada permintaan halaman baru.\nContoh worst case untuk ini : Client ingin mendapatkan semua data dengan cara melakukan scan dari page 1 sampai dengan page terakhir. Melihat behaviornya, hal ini biasanya diperlukan oleh service lain yang menjadikan service kita sebagai data sourcenya.\nBayangkan kita ingin membaca sebuah buku yang sangat tebal halaman demi halaman. Jika kita menggunakan metode LIMIT dan OFFSET, kita harus membuka buku dari awal setiap kali ingin membaca halaman berikutnya. Ini tentu sangat tidak efisien, karena kita akan mengulang-ulang membuka halaman yang sama. Dalam konteks database, hal ini sama dengan membuat database bekerja lebih keras dari yang seharusnya. Oleh karena itu, jika tujuannya adalah mendapatkan semua data, lebih baik kita langsung mengambil seluruh buku (data) sekaligus tanpa pagination, lalu membacanya (memprosesnya) di aplikasi.\nDampak Query COUNT(*) terhadap Performa Tidak hanya itu, dalam implementasi pagination menggunakan LIMIT dan OFFSET, query SELECT COUNT(*) sering digunakan untuk menghitung jumlah total baris dalam dataset. Informasi ini diperlukan untuk menyusun metadata pagination, seperti jumlah total halaman dan jumlah total item, yang kemudian dikembalikan dalam respon API.\nSebagai contoh, respon API mungkin memiliki struktur sebagai berikut:\n{ \u0026#34;message\u0026#34;: \u0026#34;successfully fetch data\u0026#34;, \u0026#34;data\u0026#34;: [ {} ], \u0026#34;meta\u0026#34;: { \u0026#34;current_page\u0026#34;: 1, \u0026#34;page_size\u0026#34;: 100, \u0026#34;total_count\u0026#34;: 3000, \u0026#34;total_page\u0026#34;: 30 }, \u0026#34;trace_id\u0026#34;: \u0026#34;5b427ba9ab30002d347ea17cf8000cca\u0026#34; } Untuk menghasilkan metadata ini, backend perlu melakukan dua query:\nUntuk mengambil data dengan LIMIT dan OFFSET SELECT * FROM users LIMIT 100 OFFSET 0; Untuk menghitung jumlah total baris dengan COUNT(*) SELECT COUNT(*) FROM users; Kejutannya, Penggunaan COUNT(*) pada dataset yang besar dapat mengakibatkan penurunan performa yang signifikan. Hal ini dikarenakan:\nFull table scan: Database perlu memindai seluruh tabel untuk menghitung jumlah baris, terutama jika tidak ada indeks yang sesuai. Kurangnya optimasi indeks: COUNT(*) seringkali tidak dapat dioptimalkan dengan indeks, sehingga waktu eksekusi query menjadi lebih lama. Masalah concurency dan locking: Query COUNT(*) dapat menyebabkan lock dengan query lain dan menghambat kinerja sistem. Beban I/O yang tinggi: Proses penghitungan jumlah baris memerlukan banyak operasi baca-tulis pada disk database. Masalah ini mungkin tidak terlihat jelas pada awal pengembangan, tetapi akan semakin terasa ketika volume data terus bertambah. Maka dari itu saya sangat merekomendasikan agar kita dapat menentukannya teknik pagination yang paling sesuai sejak awal pengembangan. Teknik alternatif dan optimasi dapat menjadi solusi yang baik untuk mengatasinya.\nOptimasi Database Query LIMIT OFFSET Ternyata query untuk pagination dengan LIMIT OFFSET masih dapat dioptimalkan. Bagaimana caranya ? Teknik ini justru saya temukan di library yang digunakan pada bahasa lain, PHP Laravel. yang dapat dicontoh pada library ini : https://github.com/hammerstonedev/fast-paginate Apa yang dilakukan untuk membuat peformanya menjadi lebih baik ?\nselect * from users -- The full data that you want to show your users. where users.id in ( -- The \u0026#34;deferred join\u0026#34; or subquery, in our case. select id from users -- The pagination, accessing as little data as possible - ID only. limit 15 offset 150000 ) Idenya adalah agar melakukan penerapan LIMIT dan OFFSET pada data yang scopenya lebih kecil, baru kemudian hasilnya dicari untuk membuat data yang lengkap.\nNamun query SELECT COUNT(*) belum tentu dapat dioptimalkan. Jadi, teknik optimasi pada query LIMIT OFFSET ini tidak sepenuhnya menyelesaikan masalah yang saya alami, terutama untuk query SELECT COUNT(*) pada dataset besar. Hal ini terlihat pada hasil monitoring yang saya lakukan.\nHasil monitoring menunjukkan perbedaan kinerja yang signifikan antara query untuk mengambil data vs query COUNT(*), Khususnya ketika banyak request yang masuk secara bersamaan.\nHal ini juga didukung oleh problem-problem serupa yang dibahas di internet seperti :\nhttps://stackoverflow.com/questions/55018986/postgresql-select-count-query-takes-long-time https://www.reddit.com/r/PostgreSQL/comments/140b4xy/select_count_is_slow_in_large_tables/ https://tunghatbh.medium.com/postgresql-slow-count-query-c93c30792606 Dari studi kasus ini, saya menarik beberapa kesimpulan penting:\nJumlah N query tidak selalu menentukan kinerja: Tidak selalu benar bahwa semakin sedikit jumlah permintaan query yang kita jalankan, semakin baik performanya. Dalam beberapa kasus, membagi query kompleks menjadi beberapa query yang lebih kecil justru dapat meningkatkan kinerja secara keseluruhan. Indeks tidak selalu optimal untuk COUNT(*): Meskipun indeks dapat meningkatkan kinerja query secara umum, pada kasus COUNT(*) indeks tidak selalu efektif. Pentingnya benchmarking: Membandingkan kinerja sebelum dan sesudah perubahan query adalah cara yang paling akurat untuk mengukur dampak dari suatu optimasi. Karena beda query dan struktur datanya, bisa jadi memerlukan cara optimasi yang berbeda pula. Cursor ! Sebagai Alternatif dari Limit Offset Penjelasan Cursor-based Pagination Cursor-based pagination menggunakan nilai unik dari suatu kolom (biasanya kolom yang diurutkan) sebagai \u0026ldquo;cursor\u0026rdquo; untuk menandai posisi saat ini dalam hasil query. Alih-alih menggunakan offset, kita mengirimkan cursor dari hasil sebelumnya untuk mendapatkan halaman berikutnya. Ini lebih efisien karena database dapat melompati nilai dan hanya perlu mencari rekaman yang memiliki nilai cursor lebih besar dari nilai cursor sebelumnya.\nSELECT * FROM users WHERE sort_column \u0026gt; \u0026#39;cursor_value\u0026#39; ORDER BY sort_column LIMIT 10; Kelebihan Cursor-based Pagination Performa lebih baik: Tidak perlu memindai seluruh tabel untuk setiap permintaan halaman. Hasil yang konsisten: Hasil query selalu sama, terlepas dari perubahan data yang terjadi di antara permintaan. Misalnya pagination pada LIMIT OFFSET akan tidak konsisten jika data pada halaman sebelumnya ada yang dihapus. UX infinity Loading: Cursor pagination sangat cocok untuk user experience web dan mobile yang biasanya menerapkan infinity loading. Kekurangan Cursor-based Pagination Implementasi lebih kompleks: Membutuhkan perencanaan yang matang dalam memilih kolom cursor yang tepat. Tidak cocok untuk semua jenis query dan UX: Hanya efektif untuk query yang diurutkan berdasarkan satu atau beberapa kolom. Statefull: Karna harus meneruskan cursor Sorting menyatu dengan cursor: Bahwa urutan data yang ditampilkan selalu berbanding lurus dengan cursor yang digunakan. Contoh Implementasi Sebagai contoh, respon API dengan cursor pagination mungkin memiliki struktur sebagai berikut:\nEndpoint : {baseURL}/users?limit=3\u0026amp;cursor= Query Param : limit: jumlah data yang ditampilkan. cursor: inputan cursor, untuk halaman pertama di isi kosong. cursor_type: field apa yang dijadikan cursor, biasanya memiliki default value, dalam contoh ini menggunakan ulid descending. { \u0026#34;message\u0026#34;: \u0026#34;successfully fetch data\u0026#34;, \u0026#34;data\u0026#34;: [ { \u0026#34;ulid\u0026#34;: \u0026#34;01J4EXF94RZA4AZG1C0A0C2RKF\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;muchlis\u0026#34; }, { \u0026#34;ulid\u0026#34;: \u0026#34;01J4EXF94RWZVWS9NVEZMQ3R1N\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;monkey d luffy\u0026#34; }, { \u0026#34;ulid\u0026#34;: \u0026#34;01J4EXF94RT7G5CRH047MC0EF1\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;portgas d ace\u0026#34; } ], \u0026#34;meta\u0026#34;: { \u0026#34;current_cursor\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;next_cursor\u0026#34;: \u0026#34;01J4EXF94RT7G5CRH047MC0EF1\u0026#34;, \u0026#34;next_page\u0026#34;: \u0026#34;/users?limit=3\u0026amp;cursor=01J4EXF94RT7G5CRH047MC0EF1\u0026#34;, \u0026#34;prev_cursor\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;prev_page\u0026#34;: \u0026#34;/users?limit=3\u0026amp;cursor=\u0026#34; }, \u0026#34;trace_id\u0026#34;: \u0026#34;5b427ba9ab30002d347ea17cf8000cca\u0026#34; } Repo Layer :\nSaya menggunakan raw query demi keterbacaan yang lebih mudah. Namun di kenyataan saya bisanya menggunakan sql builder seperti golang squirell atau goqu.\nfunc (r *repo) FetchUserByUlid(ctx context.Context, cursorID string, limit uint64) ([]entity.User, error) { ctx, cancel := context.WithTimeout(ctx, 2*time.Second) defer cancel() var sqlStatement string var args []interface{} if cursorID != \u0026#34;\u0026#34; { sqlStatement = ` SELECT id, name FROM users WHERE id \u0026lt; $1 ORDER BY id DESC LIMIT $2; ` args = append(args, cursorID, limit) } else { sqlStatement = ` SELECT id, name FROM users ORDER BY id DESC LIMIT $1; ` args = append(args, limit) } // Execute the query rows, err := r.db.Query(ctx, sqlStatement, args...) if err != nil { return nil, fmt.Errorf(\u0026#34;failed to execute query: %w\u0026#34;, err) } defer rows.Close() users := make([]entity.User, 0) // [SKIP] Parse the results // [SKIP] Check for errors after iterating over rows return users, nil } Service Layer :\nPada service layer, terdapat logic dimana kita harus mendapatkan data lebih daripada yang akan ditampilkan untuk mengetahui apakah data selanjutnya itu ada atau tidak.\nfunc (s *Service) FetchAllUsersWithCursor(ctx context.Context, cursor string, limit uint64) ([]entity.User, *string /*next cursor*/, error) { // [SKIP] validation, tracer dan sebagainya // Panggil repo layer untuk mengambil data // Menambahkan Limit +1 sehingga kita tau ada data lanjutan atau tidak // Data berlebih ini akan dibuang kemudian results, err := s.repo.FetchUserByUlid(ctx, cursor, limit+1) if err != nil { return nil, nil, fmt.Errorf(\u0026#34;error FetchUserByUlid: %w\u0026#34;, err) } // Menentukan cursor selanjutnya var nextCursor *string if len(results) \u0026gt; int(limit) { nextCursorID := results[limit-1].ID // Set cursor apabila ditemukan data lebih dari limit nextCursor = \u0026amp;nextCursorID results = results[:limit] // Hapus data yang kelebihan } else { nextCursor = nil // Jika tidak ada kelebihan data, cursor selanjutnya diset nil } // [SKIP] Konversi hasil return results, nextCursor, nil } Dengan asumsi menggunakan Clean Architecture atau Hexagonal Architecture\n+-------------------------------------+ | HTTP Handler | | (Handling HTTP requests and | | responses, routing, etc.) | +----------------+--------------------+ | v +----------------+--------------------+ | Service | | (Business logic, orchestrating the | | application flow, validation, | | calling Repositories) | +----------------+--------------------+ | v +----------------+--------------------+ | Repository | | (Data access layer, interacting with| | the database, etc.) | +-------------------------------------+ Pada contoh code di atas tersisa layer HTTP Handler yang bertugas sebagai View, dimana layer tersebut yang bertanggung jawab membuat value-value lain hasil dari proses layer service seperti menyimpan sementara current_cursor, membuat nilai next_page dari return value FetchAllUsersWithCursor() dan berbagai value lain untuk response yang memerlukan Framework HTTP Handler.\nTadi adalah contoh implementasi cursor pagination yang disederhanakan sehingga kita mendapatkan sedikit gambaran tentang kerumitannya. Pun pada code diatas saya sengaja melewatkan beberapa hal berikut karena bersifat optional.\nPrevious_Page memerlukan implementasi yang berkebalikan pada Query SQL. Alih alih menggunakan cursor dan order default WHERE id \u0026lt; $1 ORDER BY id DESC, menjadi WHERE id \u0026gt; $1 ORDER BY id ASC dengan cursor adalah value pertama dari data yang ditampilkan pada current page. Adanya kemungkinan cursor dan urutan yang memerlukan 2 key bahkan lebih. Validasi value yang lebih ketat untuk tipe Cursor dan OrderBy. Benchmark : Analisis:\nLimit-Offset Pagination memiliki waktu respon yang mulai meningkat signifikan setelah halaman ke-50 (artinya di kedalaman data 50_000), menunjukkan skala yang buruk untuk dataset besar. Limit-Offset + Query Count Pagination (dijalankan bersamaan dengan goroutine) Sedikit lebih lambat dari Limit-Offset biasa, yang menunjukkan adanya overhead tambahan. Overhead tambahan dari count ini akan terasa ketika request dijalankan secara paralel. Sedangkan pengujian diatas dilakukan secara sequensial. Cursor Pagination paling efisien dan stabil, cocok untuk dataset besar dengan jumlah halaman yang banyak. Catatan :\nKomparasi ini membandingkan semua metode menggunakan spesifikasi dan kondisi yang seragam. Latensi jaringan, struktur dan jumlah data dapat mempengaruhi hasil. Jadi, cukup berpatokan pada perbandingannya saja, karena angkanya akan sangat bervariasi tergantung kondisi masing-masing. Data yang digunakan mencakup 100_000 entri data user yang di left-join kan dengan 2 table kecil dengan percobaan pagination ekstrem pada 1_000 entri per halaman. Pengujian dilakukan secara sequensial, page per page. Pengujian ini tidak menyertakan faktor lain yang sebenarnya penting seperti penggunaan memori, CPU, Row yang dikomputasi pada database. Disini saya berusaha membuat effort seminimal mungkin. Secara teori saja sebenarnya kita dapat memperkirakan metode mana yang lebih unggul. Benchmark ini mengonfirmasi hal tersebut. Limit-Offset Pagination memiliki keunggulan berupa kemudahan implementasi, dengan kelemahan yang hanya akan dirasakan ketika aplikasi kita mencapai level dimana jumlah data menjadi sangat besar. Kelemahan ini juga bisa diatasi dengan cara memberikan indexed range dan filtering data yang sudah ditentukan kepada user (seperti saat menampilkan data transaksi bank yang wajib menentukan bulannya).\nDi sisi lain, walaupun lebih cepat dan stabil, Cursor-Based Pagination sedikit lebih rumit untuk diimplementasikan dan memiliki keterbatasan tertentu yang mungkin membuatnya kurang cocok untuk semua jenis kasus.\nPepatah premature optimization is the root of all evil mengingatkan kita bahwa optimasi yang terlalu dini bisa menjadi masalah, namun disini menurut saya pribadi, menghindari kesalahan sejak awal bukan berarti hal yang buruk juga. Justru, mengambil keputusan arsitektur dan desain yang optimal, seperti memilih Cursor-Based Pagination daripada Limit-Offset, dapat dianggap sebagai pengambilan keputusan yang bijak, bukan sekadar premature optimization. Pada intinya, memahami trade-off dari setiap pilihan dan memilih solusi yang tepat untuk kebutuhan spesifik adalah pendekatan yang lebih tepat dalam pengembangan perangkat lunak.\n","permalink":"https://blog.muchlis.dev/post/pagination/","summary":"\u003cp\u003ePagination adalah teknik dalam membagi hasil query database menjadi bagian-bagian yang lebih kecil. Menggunakan Query LIMIT OFFSET adalah metode yang paling umum digunakan. Namun, metode ini ternyata memiliki beberapa kelemahan, terutama dalam hal performa pada dataset yang sangat besar. Artikel ini akan membahas masalah-masalah yang akan muncul saat menggunakan LIMIT OFFSET dan mengeksplorasi alternatif yang lebih efisien, seperti cursor-based pagination dan seek method.\u003c/p\u003e","title":"Optimasi Pagination: Mengapa Limit-Offset Bisa Menjadi Bom Waktu dan Cursor Pagination Menjadi Solusinya"},{"content":"Seringkali, program golang yang kita buat tidak hanya berupa server Rest-API saja, tetapi juga mencakup fungsi lain seperti Event Consumer, Scheduller, CLI Program, Backfill Database, atau kombinasi dari semuanya. Pedoman project struktur ini dapat kita gunakan untuk memungkinkan semua itu. Struktur ini berfokus pada pemisahan logika inti dari ketergantungan eksternal, sehingga memungkinkan penggunaan ulang kode dalam berbagai mode aplikasi.\nLink Repository : https://github.com/muchlist/templaterepo\nPrinsip dan tujuan : Konsistensi Pengembangan: Menyediakan metode yang seragam dalam membangun aplikasi untuk meningkatkan pemahaman dan kolaborasi tim. Modularitas: Memastikan kode terpisah antar modul dan tidak tightly coupled, sehingga memudahkan pemeliharaan dan pengembangan lebih lanjut. Manajemen Dependensi yang Efektif: Dapat menghindari error siklus dependensi meskipun ada banyak modul yang saling terhubung, melalui penerapan prinsip dependency inversion. Kode yang Testable: Menerapkan prinsip arsitektur Hexagonal untuk memisahkan logika inti dari ketergantungan eksternal, sehingga dapat meningkatkan fleksibilitas dan kemudahan pengujian. Konseptual Hexagonal Architecture Arsitektur hexagonal, juga dikenal sebagai arsitektur port dan adapter, berfokus pada pemisahan core logika dari ketergantungan eksternal. Pendekatan ini mendukung prinsip-prinsip desain yang telah disebutkan dengan memastikan bahwa core aplikasi tetap bersih dan terisolasi dari komponen eksternal.\nCore : Berisi logika bisnis aplikasi. Ports : Kumpulan abstraksi yang mendefinisikan bagaimana bagian luar sistem dapat berinteraksi dengan core. Ports dapat berupa interface yang digunakan oleh core untuk berinteraksi dengan komponen eksternal seperti database, notifikasi provider, dll. Saya biasanya menggunakan idiom golang dalam memberikan nama kepada tipe interface ini seperti storer, reader, saver, assumer. Adapters : Implementasi dari ports. Adapters menerapkan antarmuka yang didefinisikan oleh ports untuk menghubungkan core dengan komponen eksternal. Project structure ├── app │ ├── api-user │ │ ├── handler │ │ │ ├── health_check.go │ │ │ └── user.go │ │ ├── main.go │ │ └── url_map.go │ ├── consumer-user │ │ └── main.go │ └── tool-logfmt │ └── main.go ├── business │ ├── complex │ │ ├── helper │ │ │ └── formula.go │ │ ├── port │ │ │ └── storer.go │ │ ├── repo │ │ │ └── repo.go │ │ └── service │ │ └── service.go │ ├── notifserv │ │ └── service.go │ └── user │ ├── repo.go │ ├── service.go │ └── storer.go ├── conf │ ├── conf.go │ └── confs.go ├── go.mod ├── go.sum ├── migrations │ ├── 000001_create_user.down.sql │ └── 000001_create_user.up.sql ├── models │ ├── notif │ │ └── notif.go │ └── user │ ├── user_dto.go │ └── user_entity.go └── pkg ├── db-pg │ └── db.go ├── errr │ └── custom_err.go ├── mid │ └── middleware.go ├── mlog │ ├── log.go │ └── logger.go └── validate └── validate.go Folder: app/ Folder App menyimpan kode yang tidak dapat digunakan ulang. Fokus code didalam folder ini antara lain :\nTitik awal program ketika dijalankan (memulai dan menghentikan aplikasi). Menyusun kode dependency yang diperlukan program. Spesifik untuk operasi input/output. Pada kebanyakan projek lainnya, folder ini akan dinamakan dengan cmd. Dinamakan app karena posisi folder akan berada diatas (yang mana dirasa cukup bagus) dan cukup mewakili fungsi folder.\nAlih-alih menggunakan kerangka kerja seperti Cobra untuk memilih aplikasi yang dijalankan, kita menggunakan metode paling sederhana seperti menjalankan program dengan go run ./app/api-user untuk aplikasi API-USER dan go run ./app/consumer-user untuk aplikasi KAFKA-USER-CONSUMER.\nFolder: pkg/ Berisi paket-paket yang dapat digunakan ulang di mana saja, biasanya elemen dasar yang tidak terkait dengan modul bisnis, seperti logger, web framework, atau helper. Tempat untuk meletakkan library yang sudah di wrap agar mudah di mock. Lapisan aplikasi dan lapisan bisnis dapat mengimpor pkg ini.\nMenggunakan pkg/ sebagai penampung kode yang awalnya garu ingin di tempatkan dimana, terbukti dapat mempercepat proses development. Pertanyaan seperti \u0026quot;Taruh di mana?\u0026quot; akan mendapatkan jawaban \u0026quot;Taruh di pkg/.\u0026quot; secara default.\nFolder: business/ atau internal/ Berisi code yang terkait dengan logika bisnis, problem bisnis, data bisnis.\nFolder: business/{nama-domain}/* Dalam setiap domain bisnis, ada layer service (atau core dalam istilah hexagonal) yang harus tetap bersih dari pustaka eksternal. Ini mencakup lapisan untuk mengakses data persisten (repo) dan interface-interface yang berfungsi sebagai port.\nFolder: business/{nama-domain}/{subfolder} Terkadang, sebuah domain dapat menjadi sangat kompleks, sehingga perlu memisahkan service, repo, dan elemen lainnya ke dalam beberapa bagian. Dalam kasus seperti ini, kita lebih memilih untuk mengatur dan memisahkan komponen-komponen tersebut ke dalam folder yang berbeda, yang juga akan memerlukan penggunaan package yang berbeda. Misalnya, business/complex.\nFolder: models Model-model (termasuk DTO, Payload, Entitas) biasanya diletakkan di dalam package bisnis masing-masing. Namun, dalam kasus yang kompleks di mana aplikasi A membutuhkan model B dan C, kita bisa mempertimbangkan untuk menempatkan model-model tersebut di level yang lebih tinggi agar dapat diakses oleh semua bagian yang membutuhkannya.\nMemisahkan struct antara Entity, DTO, dan Model cukup penting agar fleksibilitas dan kebersihan kode tetap terjaga. Hal ini disebabkan karena:\nTidak selamanya apa yang dikonsumsi oleh logika bisnis akan sama persis dengan model database. Tidak selamanya response yang diterima user sama persis dengan tabel di database. Dan seterusnya. Rules Sangat penting untuk membuat dan memperbarui aturan yang telah disepakati agar semua pihak mengikuti pendekatan yang konsisten. Misalnya, template repositori ini didasarkan pada kemampuannya untuk menghindari kode yang terlalu terikat (tightly-coupled), maka aturan Cara Penulisan Dependensi Kode menjadi sangat penting untuk dipatuhi.\nAturan ini akan bertambah seiring berjalannya waktu. Misalnya, yang seringkali terjadi perbedaan pendapat :\nBagaimana cara melakukan database transaction di logic layer ? Seberapa dalam kondisi if else boleh dilakukan. dsb. Cara Penulisan Dependensi Kode Menggunakan Dependency Injection : Dependency Injection (DI) adalah pola desain di mana dependensi disediakan dari luar objek tersebut. Ini membantu mengelola ketergantungan antar komponen, membuat kode lebih modular, dan memudahkan pengujian. Jadi, modul yang saling ketergantungan, harus bergantung pada abstraksi.\nContoh konstruktor untuk membuat logic service user business/user/service.go\ntype UserService struct { storer UserStorer notifier NotifSender } // NewUserService memerlukan UserStorer dan NotifSender. // UserStorer dan NotifSender adalah abstraksi yang diperlukan oleh UserService // Objek yang akan memenuhi UserStorer dan NotifSender ini akan ditentukan oleh // pengaturan dependensi di folder /app. // UserStorer dan NotifSender juga dapat dibuat tiruannya untuk memudahkan pengujian func NewUserService(store UserStorer, notifier NotifSender) *UserService { return \u0026amp;UserService{storer: store, notifier: notifier} } Menerapkan Prinsip Dependency Inversion: Di lapisan business, terutama untuk bagian logic (biasanya dinamakan service.go atau usecase.go atau core), komunikasi antar layer mengandalkan abstraksi dan penerapan prinsip dependency inversion yang kuat. Dalam golang, dependensi inversi yang sesungguhnya bisa dicapai seperti penjelasan pada gambar berikut.\nMengenai posisi interface, sebaiknya diletakkan pada modul yang membutuhkannya. Hal ini pernah dibahas dalam buku 100 Go Mistake and how to avoid them dan beberapa buku lainnya.\nMisalnya, domain business/user memerlukan fungsi untuk mengirimkan notifikasi yang bisa dipenuhi oleh business/notifserv, namun tidak secara gamblang business/user mengatakan perlu business/notifserv, melainkan lebih kepada mengatakan \u0026quot;Saya perlu unit yang bisa menjalankan SendNotification()\u0026quot; \u0026ndash; titik.\nImplementasi dependensinya dapat dilihat di app/api-user/routing.go. Metode ini mencegah error siklus dependensi impor dan memastikan kode tetap tidak terlalu terikat (tightly-coupled) antar domain.\nContoh dependensi yang dibutuhkan untuk membuat core logic user business/user/storer.go:\npackage user import ( \u0026#34;context\u0026#34; modelUser \u0026#34;templaterepo/models/user\u0026#34; ) // UserStorer adalah interface yang mendefinisikan operasi yang dapat dilakukan terhadap database user. // Interface ini Merupakan milik dari layer service dan dimaksudkan ditulis pada bagian layer service // Meskipun kita tau persis implementasinya ada di business/user/repo.go, tetap layer service (core) hanya bergantung pada interface ini. // Implementasi konkret dari antarmuka ini akan ditentukan oleh pengaturan dependensi di folder /app. type UserStorer interface { Get(ctx context.Context, uid string) (modelUser.UserDTO, error) CreateOne(ctx context.Context, user *modelUser.UserEntity) error } // NotifSender adalah interface yang mendefinisikan operasi untuk mengirim notifikasi. // Interface ini Merupakan milik dari layer service dan dimaksudkan ditulis pada bagian layer service // Objek yang digunakan untuk mengirim notifikasi akan ditentukan oleh pengaturan dependensi di folder /app. type NotifSender interface { SendNotification(message string) error } Contoh konstruktor untuk membuat notif business/notifserv/service.go\npackage notifserv type NotifService struct{} // return konkrit struct, bukan interfacenya // karena NotifService tidak dikekang hanya untuk menjadi NotifSender func NewNotifServ() *NotifService { return \u0026amp;NotifService{} } // SendNotification diperlukan untuk memenuhi interface NotifSender pada service user func (n *NotifService) SendNotification(message string) error { // TODO : send notif to other server return nil } // SendWhatsapp tidak diperlukan oleh service user namun bisa jadi diperlukan oleh service lain func (n *NotifService) SendWhatsapp(message string, phone string) error { // TODO : send whatsapp return nil } Aturan Lainnya yang Disepakati Ikuti panduan gaya Uber sebagai dasar (https://github.com/uber-go/guide/blob/master/style.md). Aturan ini akan ditimpa apabila ada aturan yang tertulis disini. File konfigurasi hanya boleh diakses di main.go. Lapisan lain yang ingin mengakses konfigurasi harus menerimanya melalui parameter fungsi. Konfigurasi harus memiliki nilai default yang berfungsi di environment lokal, yang dapat ditimpa oleh file .env dan argumen pada command line. Error harus dihandle hanya sekali dan tidak boleh di abaikan. Maksudnya adalah antara di konsumsi atau di return, tetapi tidak keduanya sekaligus. contoh konsumsi : menulis error pada log, contoh return : mereturn error apabila error tidak nil. Jangan mengekspose variable dalam package, Gunakan kombinasi variabel private dan fungsi publik sebagai gantinya. Ketika kode banyak digunakan, buatlah helper.go. Namun jika digunakan di beberapa paket, buatlah paket baru (misalnya untuk mengekstrak error yang cuma ada di user, /business/user/ipkg/error_parser.go). Jika penggunaannya sangat luas, masukkan di /pkg (misalnya, pkg/slicer/slicer.go, pkg/datastructure/ds.go, pkg/errr/custom_error.go). Patuhi idiom golang. Namakan interface dengan akhiran -er atau -tor untuk menunjukkan bahwa mereka adalah interface, misalnya Writer, Reader, Assumer, Saver, Reader, Generator. (https://go.dev/doc/effective_go#interface-names). Contoh: Dalam proyek dengan tiga lapisan: UserServiceAssumer, UserStorer, UserSaver, UserLoader. Tools Makefile Makefile berisi command untuk membantu proses menjalankan aplikasi dengan cepat karena tidak harus mengingat semua command yang panjang. Berfungsi seperti alias. Caranya adalah dengan menuliskan cmd di file Makefile seperti contoh berikut.\nBaris teratas adalah comment yang akan muncul ketika memanggil helper.\n.PHONY adalah penanda agar terminal tidak menganggap command makefile sebagai akses ke file.\nrun/tidy: adalah alias untuk cmd yang ada didalam nya.\n## run/tidy: run golang formater and tidying code .PHONY: run/tidy run/tidy: @echo \u0026#39;Tidying and verifying module dependencies...\u0026#39; go mod tidy go mod verify @echo \u0026#39;Formatting code...\u0026#39; go fmt ./... Sebagai contoh, untuk menjalankan aplikasi-aplikasi yang ada di repositori ini kita bisa menggunakan command seperti dibawah ini :\n# 1. pastikan ketersediaan dependency seperti database dll. # 2. menjalankan aplikasi dengan makefile (lihat file Makefile) $ make run/api/user # command tersebut akan mengeksekusi $ go run ./app/api-user # sehingga mode http server dari aplikasi akan dijalankan pre-commit Disarankan menggunakan pre-commit (https://pre-commit.com/).\n// init pre-commit install // precommit akan di trigger setiap commit // manual pre-commit run --all-files ","permalink":"https://blog.muchlis.dev/post/structuring-project-folder/","summary":"\u003cp\u003eSeringkali, program golang yang kita buat tidak hanya berupa server Rest-API saja, tetapi juga mencakup fungsi lain seperti Event Consumer, Scheduller, CLI Program, Backfill Database, atau kombinasi dari semuanya. Pedoman project struktur ini dapat kita gunakan untuk memungkinkan semua itu. Struktur ini berfokus pada pemisahan logika inti dari ketergantungan eksternal, sehingga memungkinkan penggunaan ulang kode dalam berbagai mode aplikasi.\u003c/p\u003e\n\u003cp\u003eLink Repository : \u003ca href=\"https://github.com/muchlist/templaterepo\"\u003ehttps://github.com/muchlist/templaterepo\u003c/a\u003e\u003c/p\u003e","title":"Struktur Folder dan Aturan Penulisan Kode dalam Project Golang: Preferensi Pribadi"},{"content":"Dalam pengembangan backend dengan Golang, pengelolaan proses di background menggunakan goroutine merupakan praktik umum yang dapat meningkatkan kinerja aplikasi. Namun, terdapat beberapa masalah umum yang sering dihadapi ketika mengimplementasikan goroutine, terutama dalam hal penanganan panic, pengelolaan context, dan proses shutdown yang baik. Artikel ini akan mengulas beberapa kesalahan umum yang terkait dengan penggunaan goroutine dan cara mengatasinya.\nMasalah Umum dalam Penggunaan Goroutine Panic di dalam sub goroutine tidak termasuk dalam area recovery main goroutine. Context yang dipassing ke goroutine bisa terkena deadline atau canceled ketika main goroutine selesai dieksekusi. Gracefully shutdown masih dapat mengabaikan proses background yang sedang diproses. 1. Menangani Panic di Dalam Sub Goroutine Banyak pengembang yang beranggapan bahwa panic pada keseluruhan kode di service HTTP akan direcovery oleh middleware recovery. Padahal, recovery panic hanya berlaku pada satu goroutine. Jika kita memanggil goroutine lain, kita memerlukan kode recovery tambahan. Berikut adalah contohnya:\nfunc main() { // recovery panic untuk main program defer func() { if err := recover(); err != nil { fmt.Printf(\u0026#34;panic recovered: %s\u0026#34;, err) } }() go func() { // recovery panic untuk sub goroutine defer func() { if err := recover(); err != nil { fmt.Printf(\u0026#34;panic recovered: %s\u0026#34;, err) } }() // Berjalan di latar belakang publish(context.Background(), response) }() ... } Untuk mempermudah, kita bisa membuat helper function sebagai berikut:\nfunc Background(fn func()) { go func() { defer func() { if err := recover(); err != nil { fmt.Printf(\u0026#34;panic recovered: %s\u0026#34;, err) } }() fn() }() } Dengan menggunakan helper function ini, kode contoh sebelumnya dapat diubah menjadi:\nfunc main() { // recovery panic untuk main program defer func() { if err := recover(); err != nil { fmt.Printf(\u0026#34;panic recovered: %s\u0026#34;, err) } }() Background(func() { publish(context.Background(), response) }) ... } 2. Mengelola Context pada Goroutine Context selalu digunakan dalam program Golang untuk meneruskan data penting seperti tracing identification, request_id, dan untuk kebutuhan canceling proses. Namun, context yang diteruskan ke goroutine bisa menyebabkan masalah, terutama jika context tersebut selesai lebih cepat dari goroutine. Misalnya, context dari HTTP request diteruskan ke fungsi yang berjalan di goroutine yang berbeda. Jika context tersebut selesai, maka proses di goroutine akan dibatalkan jika aware terhadap context cancellation.\nContoh :\nfunc SampleHandler(w http.ResponseWriter, r *http.Request) { response, err := doSomeTask(r.Context(), r) if err != nil { http.Error(w, err.Error(), http.StatusInternalServerError) return } go func() { // misalnya publish memerlukan waktu 2 detik // dan aware terhadap status dari context err := publish(r.Context(), response) }() // SampleHandler selesai dalam 1 detik ... } Dengan contoh di atas, publish akan gagal dan mendapatkan error context canceled. Untuk mengatasi ini, kita bisa mengganti r.Context() dengan context.Background(). Namun, bagaimana jika kita memerlukan value di dalam context? Solusinya adalah membuat implementasi context kita sendiri:\ntype Detach struct { ctx context.Context } func (d Detach) Deadline() (time.Time, bool) { return time.Time{}, false } // signal done akan diabaikan func (d Detach) Done() \u0026lt;-chan struct{} { return nil } func (d Detach) Err() error { return nil } func (d Detach) Value(key any) any { return d.ctx.Value(key) } Dengan menggunakan context custom ini, signal cancellation dari parent context tidak akan berpengaruh, sedangkan value lainnya tetap sama. Berikut adalah penerapannya pada contoh sebelumnya:\nfunc SampleHandler(w http.ResponseWriter, r *http.Request) { response, err := doSomeTask(r.Context(), r) if err != nil { http.Error(w, err.Error(), http.StatusInternalServerError) return } go func() { // misalnya publish memerlukan waktu 2 detik // publish akan tetap dilanjutkan meskipun lebih lama daripada main func err := publish(Detach{ctx: r.Context()}, response) }() // SampleHandler selesai dalam 1 detik ... } 3. Melakukan Gracefully Shutdown dengan Goroutine Gracefully shutdown adalah proses menunggu semua proses selesai sebelum aplikasi dihentikan total. Pada HTTP server, langkah-langkahnya biasanya sebagai berikut:\nMendapatkan sinyal terminate aplikasi. Menutup HTTP server sehingga tidak ada request yang masuk. Menunggu semua proses dalam satu siklus request-response selesai. Menutup semua koneksi database. Namun, bagaimana dengan proses yang masih berjalan di goroutine? Jika proses tersebut penting (misalnya invalidate cache), kita bisa menggunakan sync.WaitGroup untuk mendeteksi masih adanya proses yang belum selesai. Berikut adalah contoh kode yang menggunakan sync.WaitGroup:\nimport ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; ) // wgProcess waitgroup for gracefully shutdown background process var wgProcess sync.WaitGroup func Background(fn func()) { wgProcess.Add(1) go func() { defer wgProcess.Done() defer func() { if err := recover(); err != nil { log.Error(fmt.Sprintf(\u0026#34;panic when run background process\u0026#34;), fmt.Errorf(\u0026#34;%s\u0026#34;, err)) } }() fn() }() } Kode ini menjamin bahwa semua proses Background tercatat mulai dan selesainya melalui waitgroup. Pada main program yang menerapkan Gracefully Shutdown, kita tambahkan wgProcess.Wait() agar prosesnya blocking sampai waitgroup-nya 0 (saat semua proses selesai dijalankan). Pastikan bahwa fungsi yang menambahkan sync.WaitGroup bisa berhenti, atau tambahkan timeout.\nDengan memahami dan mengimplementasikan solusi-solusi di atas, Anda dapat mengelola proses background dengan lebih efektif di Golang. Selalu pastikan untuk menangani panic di setiap goroutine, mengelola context dengan tepat, dan melakukan shutdown aplikasi dengan baik agar semua proses dapat selesai dengan benar.\n","permalink":"https://blog.muchlis.dev/post/safe-goroutine/","summary":"\u003cp\u003eDalam pengembangan backend dengan Golang, pengelolaan proses di background menggunakan goroutine merupakan praktik umum yang dapat meningkatkan kinerja aplikasi. Namun, terdapat beberapa masalah umum yang sering dihadapi ketika mengimplementasikan goroutine, terutama dalam hal penanganan panic, pengelolaan context, dan proses shutdown yang baik. Artikel ini akan mengulas beberapa kesalahan umum yang terkait dengan penggunaan goroutine dan cara mengatasinya.\u003c/p\u003e","title":"Perhatikan hal-hal ini jika kamu menggunakan Golang Goroutine"},{"content":"Profiling adalah proses mengukur kinerja aplikasi untuk mengidentifikasi dan menganalisis berbagai aspek yang mempengaruhi performa, seperti penggunaan CPU, memori, dan goroutine. Profiling sangat penting dalam proses pengembangan untuk memastikan aplikasi berjalan efisien dan optimal serta untuk mendeteksi anomali.\nTujuan Profiling pada artikel ini Mendeteksi kebocoran memori (memory leak). Mengetahui kode yang berjalan lambat. Mengoptimasi kode. Output profiling di golang contohnya seperti ini :\nPersiapan Modifikasi Kode\nUntuk dapat melakukan profiling yang dibutuhkan adalah mengimpor package net/http/pprof agar service kita dapat menjalankan dan mengekspose endpoint /debug/pprof . Namun, alih alih menggunakan server HTTP utama, lebih baik jika endpoint khusus debug tersebut diekspos secara terpisah agar tidak ada kebocoran data yang tidak semestinya.\nImplementasinya seperti contoh dibawah ini:\npackage main import ( \u0026#34;net/http\u0026#34; \u0026#34;net/http/pprof\u0026#34; ) func debugMux() *http.ServeMux { mux := http.NewServeMux() // Register all the standard library debug endpoints. mux.HandleFunc(\u0026#34;/debug/pprof/\u0026#34;, pprof.Index) mux.HandleFunc(\u0026#34;/debug/pprof/cmdline\u0026#34;, pprof.Cmdline) mux.HandleFunc(\u0026#34;/debug/pprof/profile\u0026#34;, pprof.Profile) mux.HandleFunc(\u0026#34;/debug/pprof/symbol\u0026#34;, pprof.Symbol) mux.HandleFunc(\u0026#34;/debug/pprof/trace\u0026#34;, pprof.Trace) return mux } func main() { config := cfg.Load() ctx := context.Background() debugPort := 4000 serverPort := 8080 // start debug server in other goroutine menggunakan port 4000 debugMux := debugMux() go func(mux *http.ServeMux) { if err := http.ListenAndServe(fmt.Sprintf(\u0026#34;0.0.0.0:%v\u0026#34;, debugPort), mux); err != nil { log.Error(\u0026#34;serve debug api\u0026#34;, err) } }(debugMux) // start main server in main goroutine menggunakan port 8080 webApi := web.New(app.logger, serverPort, config.App.Env, config.App.Name) err = webApi.Serve(app.routes()) if err != nil { log.Error(\u0026#34;serve web api\u0026#34;, err) } } pada contoh diatas, kita menjalankan dua server HTTP. yaitu port 4000 untuk debug/profiling dan 8080 untuk program utama.\nMengujicoba Endpoint Debug.\nketika server dijalankan, melakukan hit ke endpoint http://localhost:4000/debug/pprof/ akan menampilkan halaman web seperti berikut :\nPada halaman ini, kita dapat mengetahui keuntungan apa saja dan data apa saja yang bisa kita analisa dari endpoint ini.\nPada umumnya yang digunakan adalah\nallocs : untuk menganalisa memory berdasarkan sample heap: untuk menganalisa memory pada program yang sedang berjalan profile: untuk menganalisa penggunaan CPU. Requirement Tools.\nUntuk menganalisa, kita menggunakan pprof yang bisa dijalankan dengan perintah go tool pprof \u0026lt;file/url\u0026gt;\nTools tambahan lainnya adalah Graphviz (untuk membuat grafik)\n# ubuntu apt-get install graphviz gv # mac brew install graphviz Cara melakukan Memory Profiling Mendapatkan Sample Data Heap/Allocs. Perintah dibawah akan menghasilkan sebuah file bernama heap.out :\ncurl -s -v http://localhost:4000/debug/pprof/heap \u0026gt; heap.out Mulai Analisa File Tadi dengan pprof\ngo tool pprof heap.out Perintah yang biasa digunakan:\ntop : untuk menampilkan data teratas penggunaan memory teratas. top50 : untuk menampilkan hasil teratas sesuai jumlah angka (Top n). top -cum : untuk menampilkan data teratas dengan urutan memori kumulatif. png : untuk menampilkan visualisasi data profiling menjadi gambar dengan format png. web: untuk menampilkan visualisasi melalui browser list : untuk menganalisa nama fungsi secara lebih detail. Hint:\nflat menunjukkan jumlah memori atau waktu CPU yang dihabiskan oleh fungsi tersebut secara langsung, bukan oleh fungsi yang dipanggil olehnya. cum (cumulative) menunjukkan jumlah total memori atau waktu CPU yang dihabiskan oleh fungsi tersebut dan semua fungsi yang dipanggil olehnya (secara rekursif). Umumnya semua penggunaan memory bisa terlihat dengan perintah png atau web yang akan menampilkan grafik seperti berikut ini. Gambar dibawah ini adalah penggunaan yang cukup normal. Jika terjadi memory leak kita bisa dengan mudah melihat kotak besar yang sangat mencolok yang dari waktu kewaktu akan terus membesar :\nuntuk lebih detail, gunakan pprof menggunakan terminal :\nMenggunakan perintah top20 -cum akan menampilkan fungsi apa saja yang menggunakan memori secara kumulatif (dijumlahkan dengan fungsi-fungsi pada tumpukan di bawahnya). Kita bisa mengabaikan jumlah pemakaian yang wajar. Misalnya, go-chi sangat wajar mengendap memori sebesar 19MB karena baru saja dilakukan load test pada service ini.\nMisal, anggaplah jack/chunkreader mencurigakan. maka tahap selanjutnya kita bisa jalankan perintah list github.com/jackc/chunkreader/v2.* (perintah list menggunakan pattern regex)\nsehingga menampilkan\nDari sana kita bisa melihat fungsi mana saja yang dirasa kurang optimal jika memang angkanya tidak pas.\nCara melakukan CPU Profiling Agak berbeda dengan memory profiling, pengujian CPU harus di-trigger dan dilakukan load pada saat pengambilan data samplenya aktif.\nPerintah berikut akan mengaktifkan collect profilling CPU selama 5 detik. (meski saat pengujian tetap dikoleksi selama 30s)\ngo tool pprof http://localhost:4000/debug/pprof/profile\\?second\\=5 Disaat yang bersamaan, lakukan load test. Bisa menggunakan hey, jmeter atau tools load test lainnya.\nHasilnya akan seperti berikut\nPada data di atas, saya mengecek middleware buatan sendiri yang ternyata proses lamanya adalah di next.ServeHTTP, yang mana itu wajar karena perhitungan kumulatif (di bawah fungsi tersebut akan dijalankan program yang sebenarnya, yaitu menuju handler → service → repo).\nSample gambar jika melakukan command png:\nGarbage Collector Menganalisa performa juga bisa dilihat dari jumlah Garbage Collector (GC) Cycle yang dijalankan dan juga alokasi memori setelah dan sebelum GC. Banyaknya GC Cycle yang berjalan bisa menjadi pertanda penggunaan alokasi memori yang tidak optimal, meskipun tidak selalu. Berikut caranya:\nJalankan program dengan command berikut ini:\n# Build dulu program kita go build ./app/api # Command untuk menjalankan program namun hanya menampilkan log gc GODEBUG=gctrace=1 ./api \u0026gt; /dev/null Log yang di-print pada terminal adalah seperti ini:\ngc 1 @0.005s 3%: 0.007+1.6+0.028 ms clock, 0.063+0.12/1.2/0.25+0.22 ms cpu, 3-\u0026gt;4-\u0026gt;1 MB, 4 MB goal, 0 MB stacks, 0 MB globals, 8 P gc 2 @0.010s 3%: 0.024+0.96+0.002 ms clock, 0.19+0/1.2/0.34+0.022 ms cpu, 3-\u0026gt;3-\u0026gt;2 MB, 4 MB goal, 0 MB stacks, 0 MB globals, 8 P gc 3 @0.014s 3%: 0.087+1.4+0.005 ms clock, 0.70+0/1.0/1.8+0.044 ms cpu, 5-\u0026gt;5-\u0026gt;5 MB, 5 MB goal, 0 MB stacks, 0 MB globals, 8 P gc 4 @0.061s 1%: 0.090+1.0+0.019 ms clock, 0.72+0.082/1.4/0+0.15 ms cpu, 11-\u0026gt;11-\u0026gt;10 MB, 12 MB goal, 0 MB stacks, 0 MB globals, 8 P Cara Membaca log:\ngc 4 artinya selama proses dihidupkan, GC sudah berjalan 4 kali. 11-\u0026gt;11-\u0026gt;10 menunjukkan ukuran heap sebelum GC, setelah GC, dan ukuran heap yang masih hidup setelah GC dalam MB (Megabyte). 0.090+1.0+0.019 ms clock menunjukkan waktu yang dihabiskan dalam milidetik (ms) untuk tiga fase utama GC: 0.090 ms untuk mark. 1.0 ms untuk sweep. 0.019 ms untuk waktu stop-the-world (STW). 0.72+0.082/1.4/0+0.15 ms cpu menunjukkan penggunaan CPU dalam milidetik (ms) selama fase GC. 3-\u0026gt;4-\u0026gt;1 MB menunjukkan ukuran heap sebelum GC, setelah GC, dan ukuran heap yang masih hidup setelah GC dalam MB. 4 MB goal adalah target ukuran heap. 0 MB stacks, 0 MB globals menunjukkan memori yang digunakan oleh stack dan global variables. 8 P menunjukkan jumlah prosesor (goroutine scheduler threads) yang digunakan. Analisa performa GC:\nSaat program berjalan, test menggunakan hey atau tool serupa, misalnya dengan 10.000 request dan lihat berapa jumlah GC yang dihasilkan. Catat request per second untuk perbandingan Jalankan profiling seperti sebelumnya. go tool pprof http://localhost:4000/debug/pprof/alloc # cari yang paling banyak menggunakan memory top 40 -cum list \u0026lt;name_func\u0026gt; Heap analysis:\nLihat heap apakah tetap kecil atau membesar, jika membesar maka kemungkinan ada memory leak. Setelah melakukan perubahan (jika ada) ujicoba lagi dari step 1 dan bandingkan jumlah GC Cycle-nya. Perbandingan Performa:\nPastikan penggunaan memori sudah efisien dengan melihat jumlah GC cycle yang terjadi, alokasi heap sebelum dan sesudah GC cycle, serta waktu GC dan waktu stop-the-world (STW). Goalnya adalah peningkatan performa yang bisa dibuktikan dengan perbandingan terhadap kode sebelumnya. Caranya bisa dengan membandingkan request per second. Bagaimana Kita Tahu Kode yang Kita Ubah Menjadi Lebih Baik? Melakukan profiling seperti diatas dan membandingkan hasilnya.\nMenggunakan tools seperti hey untuk load test dan membandingkan outputnya, misalnya request per second. Catat hasil sebelum diubah dan sesudah diubah.\nMelihat peforma Garbage Collector ketika dilakukan load test.\nArtikel ini menguraikan langkah-langkah penting untuk melakukan profiling di Golang, mulai dari persiapan, modifikasi kode, hingga analisis hasil profiling untuk mengoptimalkan performa aplikasi.\n","permalink":"https://blog.muchlis.dev/post/profiling/","summary":"\u003cp\u003eProfiling adalah proses mengukur kinerja aplikasi untuk mengidentifikasi dan menganalisis berbagai aspek yang mempengaruhi performa, seperti penggunaan CPU, memori, dan goroutine. Profiling sangat penting dalam proses pengembangan untuk memastikan aplikasi berjalan efisien dan optimal serta untuk mendeteksi anomali.\u003c/p\u003e","title":"Teknik Profiling di Golang"}]